[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/pyspark-blog/danl_320_hw1_blog_post.html",
    "href": "posts/pyspark-blog/danl_320_hw1_blog_post.html",
    "title": "PySpark Basics",
    "section": "",
    "text": "Hadoop provides storage and ways to easily process big data sets. Storage is managed by the Hadoop Distributed File System (HDFS), and the data is processed using MapReduce.  - HDFS divides up data from multiple sources and distributes them across different servers to be processed.The computing environment is redundant, allowing the application to run if a server fails.  - MapReduce distributes data across multiple machines and the brings the processed data back together so it’s coherent.\nHadoop has its limits, however. Data cannot be processed in real time. It can only collect data for a certain period of time and then process it all at once. This process is called batch processing."
  },
  {
    "objectID": "posts/pyspark-blog/danl_320_hw1_blog_post.html#pyspark-in-google-colab",
    "href": "posts/pyspark-blog/danl_320_hw1_blog_post.html#pyspark-in-google-colab",
    "title": "PySpark Basics",
    "section": "PySpark in Google Colab",
    "text": "PySpark in Google Colab\nPySpark is very similar to Pandas. It is very convenient to transform data just like we learned before, just with a slightly different syntax. Here are the basics of coding with PySpark: \n\nLoading Data \nEvery time you use PySpark, you must establish a SparkSession entry point. This allows you to transform DataFrames and SQL tables.\n\nimport pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n\nThere are two ways to approach reading a CSV file. First, if the file is in your local directory, follow this syntax that is similar to Pandas:\n\npath = '/content/drive/MyDrive/lecture-data/cces.csv'\ndf = spark.read.csv(path,\n                    inferSchema=True,\n                    header=True)\ndf.show()\n\n\nNote: in order to see any display of a DataFrame at any point while you’re working with it, you must use .show(). \n\nSecond, if the file is from a URL, you have to create a Pandas DataFrame first. From there, you can convert the Pandas DataFrame into a Spark DataFrame.\n\nimport pandas as pd\ndf_pd = pd.read_csv('https://bcdanl.github.io/data/nba.csv')\n\ndf = spark.createDataFrame(df_pd)\ndf.show()\n\n+---------------+--------------------+--------+--------+--------+\n|           Name|                Team|Position|Birthday|  Salary|\n+---------------+--------------------+--------+--------+--------+\n|   Shake Milton|  Philadelphia 76ers|      SG| 9/26/96| 1445697|\n| Christian Wood|     Detroit Pistons|      PF| 9/27/95| 1645357|\n|  PJ Washington|   Charlotte Hornets|      PF| 8/23/98| 3831840|\n|   Derrick Rose|     Detroit Pistons|      PG| 10/4/88| 7317074|\n|  Marial Shayok|  Philadelphia 76ers|       G| 7/26/95|   79568|\n| Draymond Green|Golden State Warr...|      PF|  3/4/90|18539130|\n|  Kendrick Nunn|          Miami Heat|      SG|  8/3/95| 1416852|\n|     Cedi Osman| Cleveland Cavaliers|      SF|  4/8/95| 2907143|\n|    Brook Lopez|     Milwaukee Bucks|       C|  4/1/88|12093024|\n|   Torrey Craig|      Denver Nuggets|      SF|12/19/90| 2000000|\n|Jordan Clarkson| Cleveland Cavaliers|      PG|  6/7/92|13437500|\n|    Alex Caruso|  Los Angeles Lakers|      PG| 2/28/94| 2750000|\n|   Norvel Pelle|  Philadelphia 76ers|      FC|  2/3/93|   79568|\n|  Tyler Johnson|        Phoenix Suns|      PG|  5/7/92|19245370|\n|     Alec Burks|Golden State Warr...|      SG| 7/20/91| 2320044|\n| JaMychal Green|Los Angeles Clippers|      PF| 6/21/90| 4767000|\n|  Dwight Howard|  Los Angeles Lakers|       C| 12/8/85| 5603850|\n|   Nikola Jokic|      Denver Nuggets|       C| 2/19/95|27504630|\n|  Chris Boucher|     Toronto Raptors|      PF| 1/11/93| 1588231|\n|  Marcus Morris|     New York Knicks|      PF|  9/2/89|15000000|\n+---------------+--------------------+--------+--------+--------+\nonly showing top 20 rows\n\n\n\n\n\nSummarizing Data \n\ndf.printSchema() prints column names and data types \n\nthe argument, nullable = True allows columns with a null value to print\n\ndf.columns prints list of columns \ndf.dtypes returns a list of tuples containing the column name and data type \ndf.count() prints the total number of rows \ndf.describe() prints summary statistics for each column \n\n\n\nDisplaying Data \n\ndf.show(): default shows the first 20 rows \n\narguments: \n\n\nn = : number of rows to display \ntruncate = : either boolean value, or a number specifying how many characters to keep \nvertical = : boolean value; if True, each row is displayed vertically \n\n\n\n\nSelecting Columns \nSelecting one column:\n\ndf.select(\"Name\").show(5)\n\n+--------------+\n|          Name|\n+--------------+\n|  Shake Milton|\n|Christian Wood|\n| PJ Washington|\n|  Derrick Rose|\n| Marial Shayok|\n+--------------+\nonly showing top 5 rows\n\n\n\nSelecting multiple columns:\n\ndf.select(\"Name\", \"Team\", \"Salary\").show(5)\n\n+--------------+------------------+-------+\n|          Name|              Team| Salary|\n+--------------+------------------+-------+\n|  Shake Milton|Philadelphia 76ers|1445697|\n|Christian Wood|   Detroit Pistons|1645357|\n| PJ Washington| Charlotte Hornets|3831840|\n|  Derrick Rose|   Detroit Pistons|7317074|\n| Marial Shayok|Philadelphia 76ers|  79568|\n+--------------+------------------+-------+\nonly showing top 5 rows\n\n\n\n\n\nCounting Methods \nLike previously mentioned, you can use df.count() for a count of the entire DataFrame. You can also count specific columns. Here are two ways to do this: \n\nfrom pyspark.sql.functions import countDistinct\nnum_teams = df.select(countDistinct(\"Team\")).collect()[0][0]\nnum_teams\n\n30\n\n\nThis code shows the number of observations of the unique values in the Team column.\n\ndf.groupBy(\"Team\").count().show(5)\n\n+--------------------+-----+\n|                Team|count|\n+--------------------+-----+\n|        Phoenix Suns|   15|\n|      Boston Celtics|   16|\n|    Dallas Mavericks|   13|\n|New Orleans Pelicans|   16|\n|       Brooklyn Nets|   17|\n+--------------------+-----+\nonly showing top 5 rows\n\n\n\nThis code shows how many times each unique value in Team occurrs. \n\n\nSorting \n\ndf.orderBy() sorts values by a variable given. It can be given ascending/descending intstructions. Sorting by multiple columns requires the use of a list.\n\n\ndf.orderBy(\"Name\").show(5)\n\n+-----------------+--------------------+--------+--------+--------+\n|             Name|                Team|Position|Birthday|  Salary|\n+-----------------+--------------------+--------+--------+--------+\n|     Aaron Gordon|       Orlando Magic|      PF| 9/16/95|19863636|\n|    Aaron Holiday|      Indiana Pacers|      PG| 9/30/96| 2239200|\n|      Abdel Nader|Oklahoma City Thu...|      SF| 9/25/93| 1618520|\n|      Adam Mokoka|       Chicago Bulls|       G| 7/18/98|   79568|\n|Admiral Schofield|  Washington Wizards|      SF| 3/30/97| 1000000|\n+-----------------+--------------------+--------+--------+--------+\nonly showing top 5 rows\n\n\n\nThe default sorting is ascending.\n\nfrom pyspark.sql.functions import desc\ndf.orderBy(desc(\"Salary\")).show(5)\n\n+-----------------+--------------------+--------+--------+--------+\n|             Name|                Team|Position|Birthday|  Salary|\n+-----------------+--------------------+--------+--------+--------+\n|    Stephen Curry|Golden State Warr...|      PG| 3/14/88|40231758|\n|Russell Westbrook|     Houston Rockets|      PG|11/12/88|38506482|\n|       Chris Paul|Oklahoma City Thu...|      PG|  5/6/85|38506482|\n|        John Wall|  Washington Wizards|      PG|  9/6/90|38199000|\n|     James Harden|     Houston Rockets|      PG| 8/26/89|38199000|\n+-----------------+--------------------+--------+--------+--------+\nonly showing top 5 rows\n\n\n\n\ndf.orderBy([\"Team\", desc(\"Salary\")]).show(5)\n\n+----------------+-------------+--------+--------+--------+\n|            Name|         Team|Position|Birthday|  Salary|\n+----------------+-------------+--------+--------+--------+\n|Chandler Parsons|Atlanta Hawks|      SF|10/25/88|25102512|\n|     Evan Turner|Atlanta Hawks|      PG|10/27/88|18606556|\n|    Allen Crabbe|Atlanta Hawks|      SG|  4/9/92|18500000|\n| De'Andre Hunter|Atlanta Hawks|      SF| 12/2/97| 7068360|\n|   Jabari Parker|Atlanta Hawks|      PF| 3/15/95| 6500000|\n+----------------+-------------+--------+--------+--------+\nonly showing top 5 rows\n\n\n\n\nnsmallest and nlargest are not functions in PySpark, but there is an equivalent way to do it:\n\n\n# nsmallest example:\ndf.orderBy(\"Salary\").limit(5).show()\n\n# nlargest example:\ndf.orderBy(desc(\"Salary\")).limit(5).show()\n\n\n\nRow-Based Access \nPySpark does not use row indexing, so you have to use other ways to access rows:  1. df.limit() or df.take() takes an integer and returns a list of the number of rows  2. df.collect() returns all the reconds as a list of rows  Here is an example:\n\ndf.filter(\"Team == 'New York Knicks'\").show()\ndf.limit(5).show()\ndf.take(5)\ndf.collect()\n\n+-----------------+---------------+--------+--------+--------+\n|             Name|           Team|Position|Birthday|  Salary|\n+-----------------+---------------+--------+--------+--------+\n|    Marcus Morris|New York Knicks|      PF|  9/2/89|15000000|\n|   Damyean Dotson|New York Knicks|      SG|  5/6/94| 1618520|\n| Ignas Brazdeikis|New York Knicks|      SF|  1/8/99|  898310|\n|        Ivan Rabb|New York Knicks|      PF|  2/4/97|   79568|\n|       Kevin Knox|New York Knicks|      PF| 8/11/99| 4380120|\n|    Julius Randle|New York Knicks|       C|11/29/94|18000000|\n|Mitchell Robinson|New York Knicks|       C|  4/1/98| 1559712|\n|  Wayne Ellington|New York Knicks|      SG|11/29/87| 8000000|\n|       RJ Barrett|New York Knicks|      SG| 6/14/00| 7839960|\n|    Elfrid Payton|New York Knicks|      PG| 2/22/94| 8000000|\n|    Allonzo Trier|New York Knicks|      PG| 1/17/96| 3551100|\n|   Reggie Bullock|New York Knicks|      SF| 3/16/91| 4000000|\n|     Bobby Portis|New York Knicks|       C| 2/10/95|15000000|\n|       Taj Gibson|New York Knicks|       C| 6/24/85| 9000000|\n|  Frank Ntilikina|New York Knicks|      PG| 7/28/98| 4855800|\n|     Kadeem Allen|New York Knicks|      PG| 1/15/93|   79568|\n+-----------------+---------------+--------+--------+--------+\n\n+--------------+------------------+--------+--------+-------+\n|          Name|              Team|Position|Birthday| Salary|\n+--------------+------------------+--------+--------+-------+\n|  Shake Milton|Philadelphia 76ers|      SG| 9/26/96|1445697|\n|Christian Wood|   Detroit Pistons|      PF| 9/27/95|1645357|\n| PJ Washington| Charlotte Hornets|      PF| 8/23/98|3831840|\n|  Derrick Rose|   Detroit Pistons|      PG| 10/4/88|7317074|\n| Marial Shayok|Philadelphia 76ers|       G| 7/26/95|  79568|\n+--------------+------------------+--------+--------+-------+\n\n\n\n[Row(Name='Shake Milton', Team='Philadelphia 76ers', Position='SG', Birthday='9/26/96', Salary=1445697),\n Row(Name='Christian Wood', Team='Detroit Pistons', Position='PF', Birthday='9/27/95', Salary=1645357),\n Row(Name='PJ Washington', Team='Charlotte Hornets', Position='PF', Birthday='8/23/98', Salary=3831840),\n Row(Name='Derrick Rose', Team='Detroit Pistons', Position='PG', Birthday='10/4/88', Salary=7317074),\n Row(Name='Marial Shayok', Team='Philadelphia 76ers', Position='G', Birthday='7/26/95', Salary=79568),\n Row(Name='Draymond Green', Team='Golden State Warriors', Position='PF', Birthday='3/4/90', Salary=18539130),\n Row(Name='Kendrick Nunn', Team='Miami Heat', Position='SG', Birthday='8/3/95', Salary=1416852),\n Row(Name='Cedi Osman', Team='Cleveland Cavaliers', Position='SF', Birthday='4/8/95', Salary=2907143),\n Row(Name='Brook Lopez', Team='Milwaukee Bucks', Position='C', Birthday='4/1/88', Salary=12093024),\n Row(Name='Torrey Craig', Team='Denver Nuggets', Position='SF', Birthday='12/19/90', Salary=2000000),\n Row(Name='Jordan Clarkson', Team='Cleveland Cavaliers', Position='PG', Birthday='6/7/92', Salary=13437500),\n Row(Name='Alex Caruso', Team='Los Angeles Lakers', Position='PG', Birthday='2/28/94', Salary=2750000),\n Row(Name='Norvel Pelle', Team='Philadelphia 76ers', Position='FC', Birthday='2/3/93', Salary=79568),\n Row(Name='Tyler Johnson', Team='Phoenix Suns', Position='PG', Birthday='5/7/92', Salary=19245370),\n Row(Name='Alec Burks', Team='Golden State Warriors', Position='SG', Birthday='7/20/91', Salary=2320044),\n Row(Name='JaMychal Green', Team='Los Angeles Clippers', Position='PF', Birthday='6/21/90', Salary=4767000),\n Row(Name='Dwight Howard', Team='Los Angeles Lakers', Position='C', Birthday='12/8/85', Salary=5603850),\n Row(Name='Nikola Jokic', Team='Denver Nuggets', Position='C', Birthday='2/19/95', Salary=27504630),\n Row(Name='Chris Boucher', Team='Toronto Raptors', Position='PF', Birthday='1/11/93', Salary=1588231),\n Row(Name='Marcus Morris', Team='New York Knicks', Position='PF', Birthday='9/2/89', Salary=15000000),\n Row(Name='Kevin Huerter', Team='Atlanta Hawks', Position='SG', Birthday='8/27/98', Salary=2636280),\n Row(Name='Rui Hachimura', Team='Washington Wizards', Position='PF', Birthday='2/8/98', Salary=4469160),\n Row(Name='George Hill', Team='Milwaukee Bucks', Position='PG', Birthday='5/4/86', Salary=10133907),\n Row(Name='Nickeil Alexander-Walker', Team='New Orleans Pelicans', Position='SG', Birthday='9/2/98', Salary=2964840),\n Row(Name='Jaylen Hoard', Team='Portland Trail Blazers', Position='SF', Birthday='3/30/99', Salary=79568),\n Row(Name='Tyler Cook', Team='Cleveland Cavaliers', Position='PF', Birthday='9/23/97', Salary=79568),\n Row(Name='Otto Porter', Team='Chicago Bulls', Position='SF', Birthday='6/3/93', Salary=27250576),\n Row(Name='Langston Galloway', Team='Detroit Pistons', Position='PG', Birthday='12/9/91', Salary=7333333),\n Row(Name='Evan Turner', Team='Atlanta Hawks', Position='PG', Birthday='10/27/88', Salary=18606556),\n Row(Name='Norman Powell', Team='Toronto Raptors', Position='SG', Birthday='5/25/93', Salary=10116576),\n Row(Name='Nicolas Claxton', Team='Brooklyn Nets', Position='PF', Birthday='4/17/99', Salary=898310),\n Row(Name='Michael Frazier', Team='Houston Rockets', Position='G', Birthday='3/8/94', Salary=79568),\n Row(Name='Paul Millsap', Team='Denver Nuggets', Position='PF', Birthday='2/10/85', Salary=30000000),\n Row(Name='Furkan Korkmaz', Team='Philadelphia 76ers', Position='SG', Birthday='7/24/97', Salary=1620564),\n Row(Name='Trey Burke', Team='Philadelphia 76ers', Position='PG', Birthday='11/12/92', Salary=2028594),\n Row(Name='Bradley Beal', Team='Washington Wizards', Position='SG', Birthday='6/28/93', Salary=27093018),\n Row(Name='Thomas Bryant', Team='Washington Wizards', Position='C', Birthday='7/31/97', Salary=8000000),\n Row(Name='Dean Wade', Team='Cleveland Cavaliers', Position='PF', Birthday='11/20/96', Salary=79568),\n Row(Name='Chris Paul', Team='Oklahoma City Thunder', Position='PG', Birthday='5/6/85', Salary=38506482),\n Row(Name='Josh Hart', Team='New Orleans Pelicans', Position='SF', Birthday='3/6/95', Salary=1934160),\n Row(Name='LaMarcus Aldridge', Team='San Antonio Spurs', Position='C', Birthday='7/19/85', Salary=26000000),\n Row(Name='DaQuan Jeffries', Team='Sacramento Kings', Position='SG', Birthday='8/30/97', Salary=898310),\n Row(Name='Hamidou Diallo', Team='Oklahoma City Thunder', Position='SF', Birthday='7/31/98', Salary=1416852),\n Row(Name='Jamal Murray', Team='Denver Nuggets', Position='PG', Birthday='2/23/97', Salary=4444746),\n Row(Name='Darius Bazley', Team='Oklahoma City Thunder', Position='PF', Birthday='6/12/00', Salary=2284800),\n Row(Name='Robert Franks', Team='Charlotte Hornets', Position='F', Birthday='12/18/96', Salary=79568),\n Row(Name='Gerald Green', Team='Houston Rockets', Position='SF', Birthday='1/26/86', Salary=2564753),\n Row(Name='Thaddeus Young', Team='Chicago Bulls', Position='PF', Birthday='6/21/88', Salary=12900000),\n Row(Name='Sviatoslav Mykhailiuk', Team='Detroit Pistons', Position='SF', Birthday='6/10/97', Salary=1416852),\n Row(Name='Ian Mahinmi', Team='Washington Wizards', Position='C', Birthday='11/5/86', Salary=15450051),\n Row(Name='Deonte Burton', Team='Oklahoma City Thunder', Position='SG', Birthday='1/31/94', Salary=1416852),\n Row(Name='Markelle Fultz', Team='Orlando Magic', Position='PG', Birthday='5/29/98', Salary=9745200),\n Row(Name='Aaron Gordon', Team='Orlando Magic', Position='PF', Birthday='9/16/95', Salary=19863636),\n Row(Name='Dzanan Musa', Team='Brooklyn Nets', Position='SF', Birthday='5/8/99', Salary=1911600),\n Row(Name='Patrick McCaw', Team='Toronto Raptors', Position='SF', Birthday='10/25/95', Salary=4000000),\n Row(Name='Bismack Biyombo', Team='Charlotte Hornets', Position='C', Birthday='8/28/92', Salary=17000000),\n Row(Name='JaVale McGee', Team='Los Angeles Lakers', Position='C', Birthday='1/19/88', Salary=4000000),\n Row(Name='Juwan Morgan', Team='Utah Jazz', Position='F', Birthday='4/17/97', Salary=796806),\n Row(Name='Marc Gasol', Team='Toronto Raptors', Position='C', Birthday='1/29/85', Salary=25595700),\n Row(Name='Marcus Smart', Team='Boston Celtics', Position='PG', Birthday='3/6/94', Salary=12553571),\n Row(Name='Rudy Gobert', Team='Utah Jazz', Position='C', Birthday='6/26/92', Salary=24258427),\n Row(Name='Wesley Iwundu', Team='Orlando Magic', Position='SF', Birthday='12/20/94', Salary=1618520),\n Row(Name='Dwight Powell', Team='Dallas Mavericks', Position='C', Birthday='7/20/91', Salary=10259375),\n Row(Name='Goran Dragic', Team='Miami Heat', Position='PG', Birthday='5/6/86', Salary=19217900),\n Row(Name='Theo Pinson', Team='Brooklyn Nets', Position='SG', Birthday='11/5/95', Salary=1445697),\n Row(Name='Danilo Gallinari', Team='Oklahoma City Thunder', Position='PF', Birthday='8/8/88', Salary=22615559),\n Row(Name='Joe Ingles', Team='Utah Jazz', Position='PF', Birthday='10/2/87', Salary=11454546),\n Row(Name='Jarrett Culver', Team='Minnesota Timberwolves', Position='SG', Birthday='2/20/99', Salary=5813640),\n Row(Name='Robert Covington', Team='Minnesota Timberwolves', Position='PF', Birthday='12/14/90', Salary=11301219),\n Row(Name='Damyean Dotson', Team='New York Knicks', Position='SG', Birthday='5/6/94', Salary=1618520),\n Row(Name='Patrick Beverley', Team='Los Angeles Clippers', Position='PG', Birthday='7/12/88', Salary=12345680),\n Row(Name='Kevin Love', Team='Cleveland Cavaliers', Position='C', Birthday='9/7/88', Salary=28942830),\n Row(Name='Quinn Cook', Team='Los Angeles Lakers', Position='PG', Birthday='3/23/93', Salary=3000000),\n Row(Name='Justin Wright-Foreman', Team='Utah Jazz', Position='G', Birthday='10/27/97', Salary=79568),\n Row(Name='Noah Vonleh', Team='Minnesota Timberwolves', Position='C', Birthday='8/24/95', Salary=2000000),\n Row(Name='Tyus Jones', Team='Memphis Grizzlies', Position='PG', Birthday='5/10/96', Salary=9258000),\n Row(Name='Dewayne Dedmon', Team='Sacramento Kings', Position='C', Birthday='8/12/89', Salary=13333334),\n Row(Name='Malcolm Brogdon', Team='Indiana Pacers', Position='PG', Birthday='12/11/92', Salary=20000000),\n Row(Name='Ben McLemore', Team='Houston Rockets', Position='SG', Birthday='2/11/93', Salary=2028594),\n Row(Name='Wilson Chandler', Team='Brooklyn Nets', Position='PF', Birthday='5/10/87', Salary=2564753),\n Row(Name='Isaac Bonga', Team='Washington Wizards', Position='PG', Birthday='11/8/99', Salary=1416852),\n Row(Name='Adam Mokoka', Team='Chicago Bulls', Position='G', Birthday='7/18/98', Salary=79568),\n Row(Name='Lonzo Ball', Team='New Orleans Pelicans', Position='PG', Birthday='10/27/97', Salary=8719320),\n Row(Name='Jalen Brunson', Team='Dallas Mavericks', Position='PG', Birthday='8/31/96', Salary=1416852),\n Row(Name='John Collins', Team='Atlanta Hawks', Position='PF', Birthday='9/23/97', Salary=2686560),\n Row(Name='Marvin Williams', Team='Charlotte Hornets', Position='PF', Birthday='6/19/86', Salary=15006250),\n Row(Name='Brad Wanamaker', Team='Boston Celtics', Position='PG', Birthday='7/25/89', Salary=1445697),\n Row(Name='Donte DiVincenzo', Team='Milwaukee Bucks', Position='SG', Birthday='1/31/97', Salary=2905800),\n Row(Name='Omari Spellman', Team='Golden State Warriors', Position='PF', Birthday='7/21/97', Salary=1897800),\n Row(Name='Joe Harris', Team='Brooklyn Nets', Position='SF', Birthday='9/6/91', Salary=7666667),\n Row(Name=\"Royce O'Neale\", Team='Utah Jazz', Position='PF', Birthday='6/5/93', Salary=1618520),\n Row(Name='Deandre Ayton', Team='Phoenix Suns', Position='C', Birthday='7/23/98', Salary=9562920),\n Row(Name='Cory Joseph', Team='Sacramento Kings', Position='PG', Birthday='8/20/91', Salary=12000000),\n Row(Name='Malcolm Miller', Team='Toronto Raptors', Position='SF', Birthday='3/6/93', Salary=1588231),\n Row(Name='Justise Winslow', Team='Miami Heat', Position='PF', Birthday='3/26/96', Salary=13000000),\n Row(Name='Kevin Durant', Team='Brooklyn Nets', Position='PF', Birthday='9/29/88', Salary=37199000),\n Row(Name='Evan Fournier', Team='Orlando Magic', Position='SF', Birthday='10/29/92', Salary=17000000),\n Row(Name='Chris Silva', Team='Miami Heat', Position='PF', Birthday='9/19/96', Salary=79568),\n Row(Name='Vince Carter', Team='Atlanta Hawks', Position='PF', Birthday='1/26/77', Salary=2564753),\n Row(Name='Cody Zeller', Team='Charlotte Hornets', Position='C', Birthday='10/5/92', Salary=14471910),\n Row(Name='Brian Bowen', Team='Indiana Pacers', Position='SG', Birthday='10/2/98', Salary=79568),\n Row(Name='Aaron Holiday', Team='Indiana Pacers', Position='PG', Birthday='9/30/96', Salary=2239200),\n Row(Name='Troy Daniels', Team='Los Angeles Lakers', Position='SG', Birthday='7/15/91', Salary=2028594),\n Row(Name='Buddy Hield', Team='Sacramento Kings', Position='SG', Birthday='12/17/92', Salary=4861207),\n Row(Name='Terance Mann', Team='Los Angeles Clippers', Position='SG', Birthday='10/18/96', Salary=1000000),\n Row(Name='John Konchar', Team='Memphis Grizzlies', Position='SG', Birthday='3/22/96', Salary=79568),\n Row(Name='KZ Okpala', Team='Miami Heat', Position='SF', Birthday='4/28/99', Salary=898310),\n Row(Name='Denzel Valentine', Team='Chicago Bulls', Position='SF', Birthday='11/16/93', Salary=3377568),\n Row(Name='Marquese Chriss', Team='Golden State Warriors', Position='PF', Birthday='7/2/97', Salary=1678854),\n Row(Name='Anthony Davis', Team='Los Angeles Lakers', Position='C', Birthday='3/11/93', Salary=27093019),\n Row(Name='Nemanja Bjelica', Team='Sacramento Kings', Position='PF', Birthday='5/9/88', Salary=6825000),\n Row(Name='Chandler Parsons', Team='Atlanta Hawks', Position='SF', Birthday='10/25/88', Salary=25102512),\n Row(Name='Courtney Lee', Team='Dallas Mavericks', Position='SG', Birthday='10/3/85', Salary=12759670),\n Row(Name='Myles Turner', Team='Indiana Pacers', Position='C', Birthday='3/24/96', Salary=18000000),\n Row(Name=\"Kyle O'Quinn\", Team='Philadelphia 76ers', Position='C', Birthday='3/26/90', Salary=2174318),\n Row(Name='Bryn Forbes', Team='San Antonio Spurs', Position='SG', Birthday='7/23/93', Salary=2875000),\n Row(Name='Duncan Robinson', Team='Miami Heat', Position='PF', Birthday='4/22/94', Salary=1416852),\n Row(Name='Devin Booker', Team='Phoenix Suns', Position='SG', Birthday='10/30/96', Salary=27285000),\n Row(Name='Grant Williams', Team='Boston Celtics', Position='PF', Birthday='11/30/98', Salary=2379840),\n Row(Name='DeMarcus Cousins', Team='Los Angeles Lakers', Position='C', Birthday='8/13/90', Salary=3500000),\n Row(Name='DeMar DeRozan', Team='San Antonio Spurs', Position='SF', Birthday='8/7/89', Salary=27739975),\n Row(Name='Kristaps Porzingis', Team='Dallas Mavericks', Position='PF', Birthday='8/2/95', Salary=27285000),\n Row(Name='Brandon Knight', Team='Cleveland Cavaliers', Position='PG', Birthday='12/2/91', Salary=15643750),\n Row(Name='Thabo Sefolosha', Team='Houston Rockets', Position='PF', Birthday='5/2/84', Salary=2564753),\n Row(Name='David Nwaba', Team='Brooklyn Nets', Position='SF', Birthday='1/14/93', Salary=1678854),\n Row(Name='Quinndary Weatherspoon', Team='San Antonio Spurs', Position='G', Birthday='9/10/96', Salary=79568),\n Row(Name='Dewan Hernandez', Team='Toronto Raptors', Position='C', Birthday='12/9/96', Salary=898310),\n Row(Name='Isaiah Thomas', Team='Washington Wizards', Position='PG', Birthday='2/7/89', Salary=2320044),\n Row(Name='Bruce Brown', Team='Detroit Pistons', Position='SG', Birthday='8/15/96', Salary=1416852),\n Row(Name='Keldon Johnson', Team='San Antonio Spurs', Position='SF', Birthday='10/11/99', Salary=1950600),\n Row(Name='Damian Jones', Team='Atlanta Hawks', Position='C', Birthday='6/30/95', Salary=2305057),\n Row(Name='Luguentz Dort', Team='Oklahoma City Thunder', Position='G', Birthday='4/19/99', Salary=79568),\n Row(Name='Terence Davis', Team='Toronto Raptors', Position='SG', Birthday='5/16/97', Salary=898310),\n Row(Name='Chandler Hutchison', Team='Chicago Bulls', Position='SF', Birthday='4/26/96', Salary=2332320),\n Row(Name='Steven Adams', Team='Oklahoma City Thunder', Position='C', Birthday='7/20/93', Salary=25842697),\n Row(Name='Jordan Poole', Team='Golden State Warriors', Position='SG', Birthday='6/19/99', Salary=1964760),\n Row(Name='Sekou Doumbouya', Team='Detroit Pistons', Position='SF', Birthday='12/23/00', Salary=3285120),\n Row(Name='Zion Williamson', Team='New Orleans Pelicans', Position='F', Birthday='7/6/00', Salary=9757440),\n Row(Name='Mike Muscala', Team='Oklahoma City Thunder', Position='C', Birthday='7/1/91', Salary=2028594),\n Row(Name='Skal Labissiere', Team='Portland Trail Blazers', Position='C', Birthday='3/18/96', Salary=2338846),\n Row(Name='Meyers Leonard', Team='Miami Heat', Position='C', Birthday='2/27/92', Salary=11286515),\n Row(Name='Reggie Jackson', Team='Detroit Pistons', Position='PG', Birthday='4/16/90', Salary=18086956),\n Row(Name='Alfonzo McKinnie', Team='Cleveland Cavaliers', Position='SF', Birthday='9/17/92', Salary=1588231),\n Row(Name='Yuta Watanabe', Team='Memphis Grizzlies', Position='SF', Birthday='10/13/94', Salary=79568),\n Row(Name='Kentavious Caldwell-Pope', Team='Los Angeles Lakers', Position='SG', Birthday='2/18/93', Salary=8089282),\n Row(Name='Kelan Martin', Team='Minnesota Timberwolves', Position='SF', Birthday='8/3/95', Salary=79568),\n Row(Name='OG Anunoby', Team='Toronto Raptors', Position='SF', Birthday='7/17/97', Salary=2281800),\n Row(Name='Tyler Herro', Team='Miami Heat', Position='SG', Birthday='1/20/00', Salary=3640200),\n Row(Name='Richaun Holmes', Team='Sacramento Kings', Position='C', Birthday='10/15/93', Salary=4767000),\n Row(Name='Tyson Chandler', Team='Houston Rockets', Position='C', Birthday='10/2/82', Salary=2564753),\n Row(Name='Solomon Hill', Team='Memphis Grizzlies', Position='SF', Birthday='3/18/91', Salary=13290395),\n Row(Name='Keita Bates-Diop', Team='Minnesota Timberwolves', Position='SF', Birthday='1/23/96', Salary=1416852),\n Row(Name='Kelly Olynyk', Team='Miami Heat', Position='C', Birthday='4/19/91', Salary=12667885),\n Row(Name='Jaxson Hayes', Team='New Orleans Pelicans', Position='C', Birthday='5/23/00', Salary=4862040),\n Row(Name='CJ McCollum', Team='Portland Trail Blazers', Position='SG', Birthday='9/19/91', Salary=27556959),\n Row(Name='Darius Miller', Team='New Orleans Pelicans', Position='SF', Birthday='3/21/90', Salary=7250000),\n Row(Name='Luka Doncic', Team='Dallas Mavericks', Position='PG', Birthday='2/28/99', Salary=7683360),\n Row(Name='DeMarre Carroll', Team='San Antonio Spurs', Position='PF', Birthday='7/27/86', Salary=7000000),\n Row(Name='Cristiano Felicio', Team='Chicago Bulls', Position='C', Birthday='7/7/92', Salary=8156500),\n Row(Name='Zach LaVine', Team='Chicago Bulls', Position='PG', Birthday='3/10/95', Salary=19500000),\n Row(Name='Tremont Waters', Team='Boston Celtics', Position='PG', Birthday='1/10/98', Salary=79568),\n Row(Name='Dejounte Murray', Team='San Antonio Spurs', Position='PG', Birthday='9/19/96', Salary=2321735),\n Row(Name='Jerome Robinson', Team='Los Angeles Clippers', Position='SG', Birthday='2/22/97', Salary=3567720),\n Row(Name='Rudy Gay', Team='San Antonio Spurs', Position='PF', Birthday='8/17/86', Salary=14500000),\n Row(Name='Ryan Broekhoff', Team='Dallas Mavericks', Position='SG', Birthday='8/23/90', Salary=1416852),\n Row(Name='Jake Layman', Team='Minnesota Timberwolves', Position='PF', Birthday='3/7/94', Salary=3581986),\n Row(Name='Cameron Johnson', Team='Phoenix Suns', Position='PF', Birthday='3/3/96', Salary=4033440),\n Row(Name='Allen Crabbe', Team='Atlanta Hawks', Position='SG', Birthday='4/9/92', Salary=18500000),\n Row(Name='Justin James', Team='Sacramento Kings', Position='SG', Birthday='1/24/97', Salary=898310),\n Row(Name='Emmanuel Mudiay', Team='Utah Jazz', Position='PG', Birthday='3/5/96', Salary=1737145),\n Row(Name='Avery Bradley', Team='Los Angeles Lakers', Position='PG', Birthday='11/26/90', Salary=6767000),\n Row(Name='Victor Oladipo', Team='Indiana Pacers', Position='PG', Birthday='5/4/92', Salary=21000000),\n Row(Name='Caleb Martin', Team='Charlotte Hornets', Position='SF', Birthday='9/28/95', Salary=898310),\n Row(Name='Coby White', Team='Chicago Bulls', Position='SG', Birthday='2/16/00', Salary=5307120),\n Row(Name='Isaiah Hartenstein', Team='Houston Rockets', Position='C', Birthday='5/5/98', Salary=1416852),\n Row(Name='Will Barton', Team='Denver Nuggets', Position='SF', Birthday='1/6/91', Salary=12776786),\n Row(Name='Dwayne Bacon', Team='Charlotte Hornets', Position='SG', Birthday='8/30/95', Salary=1618520),\n Row(Name='Harrison Barnes', Team='Sacramento Kings', Position='PF', Birthday='5/30/92', Salary=24147727),\n Row(Name='Tim Frazier', Team='Detroit Pistons', Position='PG', Birthday='11/1/90', Salary=1620564),\n Row(Name='Jimmy Butler', Team='Miami Heat', Position='SF', Birthday='9/14/89', Salary=32742000),\n Row(Name='Gary Harris', Team='Denver Nuggets', Position='SG', Birthday='9/14/94', Salary=17839286),\n Row(Name='Thon Maker', Team='Detroit Pistons', Position='C', Birthday='2/25/97', Salary=3569643),\n Row(Name='Shai Gilgeous-Alexander', Team='Oklahoma City Thunder', Position='PG', Birthday='7/12/98', Salary=3952920),\n Row(Name='Hassan Whiteside', Team='Portland Trail Blazers', Position='C', Birthday='6/13/89', Salary=27093018),\n Row(Name='Karl-Anthony Towns', Team='Minnesota Timberwolves', Position='C', Birthday='11/15/95', Salary=27285000),\n Row(Name='Ky Bowman', Team='Golden State Warriors', Position='PG', Birthday='6/16/97', Salary=79568),\n Row(Name='Ben Simmons', Team='Philadelphia 76ers', Position='PG', Birthday='7/20/96', Salary=8113929),\n Row(Name='Terrence Ross', Team='Orlando Magic', Position='SF', Birthday='2/5/91', Salary=12500000),\n Row(Name='Jordan McLaughlin', Team='Minnesota Timberwolves', Position='PG', Birthday='4/9/96', Salary=79568),\n Row(Name='Daniel Theis', Team='Boston Celtics', Position='C', Birthday='4/4/92', Salary=5000000),\n Row(Name='Jonathan Isaac', Team='Orlando Magic', Position='PF', Birthday='10/3/97', Salary=5806440),\n Row(Name='Cheick Diallo', Team='Phoenix Suns', Position='C', Birthday='9/13/96', Salary=1678854),\n Row(Name='Serge Ibaka', Team='Toronto Raptors', Position='C', Birthday='9/18/89', Salary=23271604),\n Row(Name='Amile Jefferson', Team='Orlando Magic', Position='PF', Birthday='5/7/93', Salary=1339515),\n Row(Name='Cam Reddish', Team='Atlanta Hawks', Position='SF', Birthday='9/1/99', Salary=4245720),\n Row(Name=\"De'Anthony Melton\", Team='Memphis Grizzlies', Position='PG', Birthday='5/28/98', Salary=1416852),\n Row(Name='Udonis Haslem', Team='Miami Heat', Position='C', Birthday='6/9/80', Salary=2564753),\n Row(Name='Charlie Brown', Team='Atlanta Hawks', Position='SG', Birthday='2/2/97', Salary=79568),\n Row(Name='Elie Okobo', Team='Phoenix Suns', Position='PG', Birthday='10/23/97', Salary=1416852),\n Row(Name='Gordon Hayward', Team='Boston Celtics', Position='PF', Birthday='3/23/90', Salary=32700690),\n Row(Name='Marco Belinelli', Team='San Antonio Spurs', Position='SF', Birthday='3/25/86', Salary=5846154),\n Row(Name='Javonte Green', Team='Boston Celtics', Position='SF', Birthday='7/23/93', Salary=898310),\n Row(Name='Rondae Hollis-Jefferson', Team='Toronto Raptors', Position='SF', Birthday='1/3/95', Salary=2500000),\n Row(Name='Carmelo Anthony', Team='Portland Trail Blazers', Position='PF', Birthday='5/29/84', Salary=2159029),\n Row(Name='Danny Green', Team='Los Angeles Lakers', Position='SG', Birthday='6/22/87', Salary=14634147),\n Row(Name='Stephen Curry', Team='Golden State Warriors', Position='PG', Birthday='3/14/88', Salary=40231758),\n Row(Name='Eric Paschall', Team='Golden State Warriors', Position='PF', Birthday='11/4/96', Salary=898310),\n Row(Name='Daniel Gafford', Team='Chicago Bulls', Position='C', Birthday='10/1/98', Salary=898310),\n Row(Name='Anfernee Simons', Team='Portland Trail Blazers', Position='SG', Birthday='6/8/99', Salary=2149560),\n Row(Name='Frank Kaminsky', Team='Phoenix Suns', Position='C', Birthday='4/4/93', Salary=4767000),\n Row(Name='Luke Kennard', Team='Detroit Pistons', Position='SG', Birthday='6/24/96', Salary=3827160),\n Row(Name='Josh Okogie', Team='Minnesota Timberwolves', Position='SG', Birthday='9/1/98', Salary=2530680),\n Row(Name='Rodney Hood', Team='Portland Trail Blazers', Position='SF', Birthday='10/20/92', Salary=5718000),\n Row(Name=\"De'Andre Hunter\", Team='Atlanta Hawks', Position='SF', Birthday='12/2/97', Salary=7068360),\n Row(Name='Klay Thompson', Team='Golden State Warriors', Position='SG', Birthday='2/8/90', Salary=32742000),\n Row(Name='Jrue Holiday', Team='New Orleans Pelicans', Position='PG', Birthday='6/12/90', Salary=26131111),\n Row(Name='PJ Dozier', Team='Denver Nuggets', Position='PG', Birthday='10/25/96', Salary=79568),\n Row(Name='Andre Drummond', Team='Detroit Pistons', Position='C', Birthday='8/10/93', Salary=27093018),\n Row(Name='Jared Harper', Team='Phoenix Suns', Position='PG', Birthday='9/14/97', Salary=79568),\n Row(Name='Russell Westbrook', Team='Houston Rockets', Position='PG', Birthday='11/12/88', Salary=38506482),\n Row(Name='Tony Bradley', Team='Utah Jazz', Position='C', Birthday='1/8/98', Salary=1962360),\n Row(Name='Oshae Brissett', Team='Toronto Raptors', Position='SF', Birthday='6/20/98', Salary=79568),\n Row(Name='Gary Clark', Team='Houston Rockets', Position='PF', Birthday='11/16/94', Salary=1416852),\n Row(Name='Pascal Siakam', Team='Toronto Raptors', Position='PF', Birthday='4/2/94', Salary=2351838),\n Row(Name='Eric Bledsoe', Team='Milwaukee Bucks', Position='PG', Birthday='12/9/89', Salary=15625000),\n Row(Name='Tomas Satoransky', Team='Chicago Bulls', Position='PG', Birthday='10/30/91', Salary=10000000),\n Row(Name='Davis Bertans', Team='Washington Wizards', Position='PF', Birthday='11/12/92', Salary=7000000),\n Row(Name='Amir Coffey', Team='Los Angeles Clippers', Position='G', Birthday='6/17/97', Salary=79568),\n Row(Name='Ignas Brazdeikis', Team='New York Knicks', Position='SF', Birthday='1/8/99', Salary=898310),\n Row(Name='Ivan Rabb', Team='New York Knicks', Position='PF', Birthday='2/4/97', Salary=79568),\n Row(Name='Khris Middleton', Team='Milwaukee Bucks', Position='SF', Birthday='8/12/91', Salary=30603448),\n Row(Name='Kevin Knox', Team='New York Knicks', Position='PF', Birthday='8/11/99', Salary=4380120),\n Row(Name='Jeff Green', Team='Utah Jazz', Position='PF', Birthday='8/28/86', Salary=2564753),\n Row(Name='Ersan Ilyasova', Team='Milwaukee Bucks', Position='PF', Birthday='5/15/87', Salary=7000000),\n Row(Name='Caleb Swanigan', Team='Sacramento Kings', Position='PF', Birthday='4/18/97', Salary=2033160),\n Row(Name='Al Horford', Team='Philadelphia 76ers', Position='C', Birthday='6/3/86', Salary=28000000),\n Row(Name='Clint Capela', Team='Houston Rockets', Position='C', Birthday='5/18/94', Salary=16896552),\n Row(Name='Georges Niang', Team='Utah Jazz', Position='PF', Birthday='6/17/93', Salary=1645357),\n Row(Name='Wesley Matthews', Team='Milwaukee Bucks', Position='SF', Birthday='10/14/86', Salary=2564753),\n Row(Name='Rajon Rondo', Team='Los Angeles Lakers', Position='PG', Birthday='2/22/86', Salary=2564753),\n Row(Name='Delon Wright', Team='Dallas Mavericks', Position='PG', Birthday='4/26/92', Salary=9473684),\n Row(Name='Ja Morant', Team='Memphis Grizzlies', Position='PG', Birthday='8/10/99', Salary=8730240),\n Row(Name='Fred VanVleet', Team='Toronto Raptors', Position='PG', Birthday='2/25/94', Salary=9346153),\n Row(Name='Brandon Clarke', Team='Memphis Grizzlies', Position='PF', Birthday='9/19/96', Salary=2478840),\n Row(Name='Miye Oni', Team='Utah Jazz', Position='SG', Birthday='8/4/97', Salary=898310),\n Row(Name='Julius Randle', Team='New York Knicks', Position='C', Birthday='11/29/94', Salary=18000000),\n Row(Name='Glenn Robinson III', Team='Golden State Warriors', Position='SF', Birthday='1/8/94', Salary=1882867),\n Row(Name='Dillon Brooks', Team='Memphis Grizzlies', Position='SF', Birthday='1/22/96', Salary=1618520),\n Row(Name='Zylan Cheatham', Team='New Orleans Pelicans', Position='SF', Birthday='11/17/95', Salary=79568),\n Row(Name='Markieff Morris', Team='Detroit Pistons', Position='PF', Birthday='9/2/89', Salary=3200000),\n Row(Name='Malik Beasley', Team='Denver Nuggets', Position='SG', Birthday='11/26/96', Salary=2731713),\n Row(Name='John Wall', Team='Washington Wizards', Position='PG', Birthday='9/6/90', Salary=38199000),\n Row(Name='Vlatko Cancar', Team='Denver Nuggets', Position='SF', Birthday='4/10/97', Salary=898310),\n Row(Name='Alize Johnson', Team='Indiana Pacers', Position='PF', Birthday='4/22/96', Salary=1416852),\n Row(Name='Andrew Wiggins', Team='Minnesota Timberwolves', Position='SF', Birthday='2/23/95', Salary=27504630),\n Row(Name='Khyri Thomas', Team='Detroit Pistons', Position='SG', Birthday='5/8/96', Salary=1416852),\n Row(Name='Mitchell Robinson', Team='New York Knicks', Position='C', Birthday='4/1/98', Salary=1559712),\n Row(Name='Damian Lillard', Team='Portland Trail Blazers', Position='PG', Birthday='7/15/90', Salary=29802321),\n Row(Name='Nassir Little', Team='Portland Trail Blazers', Position='PF', Birthday='2/11/00', Salary=2105520),\n Row(Name='Mikal Bridges', Team='Phoenix Suns', Position='SF', Birthday='8/30/96', Salary=4161000),\n Row(Name='Kyle Anderson', Team='Memphis Grizzlies', Position='PF', Birthday='9/20/93', Salary=9073050),\n Row(Name='Garrett Temple', Team='Brooklyn Nets', Position='PG', Birthday='5/8/86', Salary=4767000),\n Row(Name='Kyle Korver', Team='Milwaukee Bucks', Position='PF', Birthday='3/17/81', Salary=6004753),\n Row(Name='Al-Farouq Aminu', Team='Orlando Magic', Position='PF', Birthday='9/21/90', Salary=9258000),\n Row(Name='James Harden', Team='Houston Rockets', Position='PG', Birthday='8/26/89', Salary=38199000),\n Row(Name='Derrick White', Team='San Antonio Spurs', Position='PG', Birthday='7/2/94', Salary=1948080),\n Row(Name='JaKarr Sampson', Team='Indiana Pacers', Position='SF', Birthday='3/20/93', Salary=1737145),\n Row(Name='Dario Saric', Team='Phoenix Suns', Position='PF', Birthday='4/8/94', Salary=3481985),\n Row(Name='Ivica Zubac', Team='Los Angeles Clippers', Position='C', Birthday='3/18/97', Salary=6481482),\n Row(Name='Juan Hernangomez', Team='Denver Nuggets', Position='PF', Birthday='9/28/95', Salary=3321029),\n Row(Name='Jarrell Brantley', Team='Utah Jazz', Position='PF', Birthday='6/7/96', Salary=79568),\n Row(Name='Eric Gordon', Team='Houston Rockets', Position='PG', Birthday='12/25/88', Salary=14057730),\n Row(Name='Naz Reid', Team='Minnesota Timberwolves', Position='F', Birthday='8/26/99', Salary=898310),\n Row(Name='Justin Robinson', Team='Washington Wizards', Position='PG', Birthday='10/12/97', Salary=898310),\n Row(Name='Grayson Allen', Team='Memphis Grizzlies', Position='SG', Birthday='10/8/95', Salary=2429400),\n Row(Name='Trevor Ariza', Team='Sacramento Kings', Position='SF', Birthday='6/30/85', Salary=12200000),\n Row(Name='Brandon Goodwin', Team='Atlanta Hawks', Position='PG', Birthday='10/2/95', Salary=79568),\n Row(Name=\"E'Twaun Moore\", Team='New Orleans Pelicans', Position='PG', Birthday='2/25/89', Salary=8664928),\n Row(Name='Mario Hezonja', Team='Portland Trail Blazers', Position='PF', Birthday='2/25/95', Salary=1737145),\n Row(Name='Henry Ellenson', Team='Brooklyn Nets', Position='PF', Birthday='1/13/97', Salary=79568),\n Row(Name='Johnathan Motley', Team='Los Angeles Clippers', Position='PF', Birthday='5/4/95', Salary=79568),\n Row(Name='James Ennis', Team='Philadelphia 76ers', Position='SF', Birthday='7/1/90', Salary=1882867),\n Row(Name='Andre Roberson', Team='Oklahoma City Thunder', Position='SF', Birthday='12/4/91', Salary=10740740),\n Row(Name='Garrison Mathews', Team='Washington Wizards', Position='SG', Birthday='10/24/96', Salary=79568),\n Row(Name='Jahlil Okafor', Team='New Orleans Pelicans', Position='C', Birthday='12/15/95', Salary=1702486),\n Row(Name='Mfiondu Kabengele', Team='Los Angeles Clippers', Position='C', Birthday='8/14/97', Salary=1977000),\n Row(Name='Treveon Graham', Team='Minnesota Timberwolves', Position='SG', Birthday='10/28/93', Salary=1645357),\n Row(Name='Seth Curry', Team='Dallas Mavericks', Position='PG', Birthday='8/23/90', Salary=7461380),\n Row(Name=\"D'Angelo Russell\", Team='Golden State Warriors', Position='PG', Birthday='2/23/96', Salary=27285000),\n Row(Name='Justin Holiday', Team='Indiana Pacers', Position='SG', Birthday='4/5/89', Salary=4767000),\n Row(Name='Tyrone Wallace', Team='Atlanta Hawks', Position='PG', Birthday='6/10/94', Salary=1620564),\n Row(Name='Miles Bridges', Team='Charlotte Hornets', Position='SF', Birthday='3/21/98', Salary=3755400),\n Row(Name='Bogdan Bogdanovic', Team='Sacramento Kings', Position='SG', Birthday='8/18/92', Salary=8529386),\n Row(Name='Matt Thomas', Team='Toronto Raptors', Position='SG', Birthday='8/4/94', Salary=898310),\n Row(Name='Jordan Bell', Team='Minnesota Timberwolves', Position='C', Birthday='1/7/95', Salary=1620564),\n Row(Name='Wenyen Gabriel', Team='Sacramento Kings', Position='PF', Birthday='3/26/97', Salary=79568),\n Row(Name='Tony Snell', Team='Detroit Pistons', Position='SF', Birthday='11/10/91', Salary=11392857),\n Row(Name='Shaquille Harrison', Team='Chicago Bulls', Position='PG', Birthday='10/6/93', Salary=1620564),\n Row(Name='Yogi Ferrell', Team='Sacramento Kings', Position='PG', Birthday='5/9/93', Salary=3150000),\n Row(Name='Mike Scott', Team='Philadelphia 76ers', Position='PF', Birthday='7/16/88', Salary=4767000),\n Row(Name='Jarred Vanderbilt', Team='Denver Nuggets', Position='PF', Birthday='4/3/99', Salary=1416852),\n Row(Name='Jeff Teague', Team='Minnesota Timberwolves', Position='PG', Birthday='6/10/88', Salary=19000000),\n Row(Name='Zach Norvell', Team='Los Angeles Lakers', Position='SG', Birthday='12/9/97', Salary=79568),\n Row(Name='Maxi Kleber', Team='Dallas Mavericks', Position='C', Birthday='1/29/92', Salary=8000000),\n Row(Name='Matisse Thybulle', Team='Philadelphia 76ers', Position='SG', Birthday='3/4/97', Salary=2582160),\n Row(Name='Ryan Arcidiacono', Team='Chicago Bulls', Position='PG', Birthday='3/26/94', Salary=3000000),\n Row(Name='Wayne Ellington', Team='New York Knicks', Position='SG', Birthday='11/29/87', Salary=8000000),\n Row(Name='Kawhi Leonard', Team='Los Angeles Clippers', Position='SF', Birthday='6/29/91', Salary=32742000),\n Row(Name='Montrezl Harrell', Team='Los Angeles Clippers', Position='C', Birthday='1/26/94', Salary=6000000),\n Row(Name='Jusuf Nurkic', Team='Portland Trail Blazers', Position='C', Birthday='8/23/94', Salary=12000000),\n Row(Name='Matthew Dellavedova', Team='Cleveland Cavaliers', Position='PG', Birthday='9/8/90', Salary=9607500),\n Row(Name='Cody Martin', Team='Charlotte Hornets', Position='SF', Birthday='9/28/95', Salary=1173310),\n Row(Name='Zhaire Smith', Team='Philadelphia 76ers', Position='SG', Birthday='6/4/99', Salary=3058800),\n Row(Name='RJ Barrett', Team='New York Knicks', Position='SG', Birthday='6/14/00', Salary=7839960),\n Row(Name='Lonnie Walker', Team='San Antonio Spurs', Position='SG', Birthday='12/14/98', Salary=2764200),\n Row(Name='Taurean Prince', Team='Brooklyn Nets', Position='SF', Birthday='3/22/94', Salary=3481985),\n Row(Name='Elfrid Payton', Team='New York Knicks', Position='PG', Birthday='2/22/94', Salary=8000000),\n Row(Name='Blake Griffin', Team='Detroit Pistons', Position='PF', Birthday='3/16/89', Salary=34449964),\n Row(Name='Marko Guduric', Team='Memphis Grizzlies', Position='SG', Birthday='3/8/95', Salary=2625000),\n Row(Name='Zach Collins', Team='Portland Trail Blazers', Position='C', Birthday='11/19/97', Salary=4240200),\n Row(Name='Stanley Johnson', Team='Toronto Raptors', Position='PF', Birthday='5/29/96', Salary=3623000),\n Row(Name='Boban Marjanovic', Team='Dallas Mavericks', Position='C', Birthday='8/15/88', Salary=3500000),\n Row(Name='Josh Magette', Team='Orlando Magic', Position='PG', Birthday='11/28/89', Salary=79568),\n Row(Name='Kyle Lowry', Team='Toronto Raptors', Position='PG', Birthday='3/25/86', Salary=33296296),\n Row(Name='Darius Garland', Team='Cleveland Cavaliers', Position='PG', Birthday='1/26/00', Salary=6400920),\n Row(Name='Frank Jackson', Team='New Orleans Pelicans', Position='PG', Birthday='5/4/98', Salary=1618520),\n Row(Name='Dragan Bender', Team='Milwaukee Bucks', Position='PF', Birthday='11/17/97', Salary=1678854),\n Row(Name='Kenrich Williams', Team='New Orleans Pelicans', Position='PF', Birthday='12/2/94', Salary=1416852),\n Row(Name='Jerami Grant', Team='Denver Nuggets', Position='PF', Birthday='3/12/94', Salary=9346153),\n Row(Name='Allonzo Trier', Team='New York Knicks', Position='PG', Birthday='1/17/96', Salary=3551100),\n Row(Name='Pat Connaughton', Team='Milwaukee Bucks', Position='SG', Birthday='1/6/93', Salary=1723050),\n Row(Name='Domantas Sabonis', Team='Indiana Pacers', Position='C', Birthday='5/3/96', Salary=3529554),\n Row(Name='Dylan Windler', Team='Cleveland Cavaliers', Position='GF', Birthday='9/22/96', Salary=2035800),\n Row(Name='Antonius Cleveland', Team='Dallas Mavericks', Position='SG', Birthday='2/2/94', Salary=79568),\n Row(Name='Damion Lee', Team='Golden State Warriors', Position='SG', Birthday='10/21/92', Salary=79568),\n Row(Name='Khem Birch', Team='Orlando Magic', Position='C', Birthday='9/28/92', Salary=3000000),\n Row(Name='Aron Baynes', Team='Phoenix Suns', Position='C', Birthday='12/9/86', Salary=5453280),\n Row(Name='Kemba Walker', Team='Boston Celtics', Position='PG', Birthday='5/8/90', Salary=32742000),\n Row(Name='Nerlens Noel', Team='Oklahoma City Thunder', Position='C', Birthday='4/10/94', Salary=1882867),\n Row(Name='Jabari Parker', Team='Atlanta Hawks', Position='PF', Birthday='3/15/95', Salary=6500000),\n Row(Name='Carsen Edwards', Team='Boston Celtics', Position='SG', Birthday='3/12/98', Salary=1228026),\n Row(Name='Anthony Tolliver', Team='Portland Trail Blazers', Position='PF', Birthday='6/1/85', Salary=2564753),\n Row(Name='Lauri Markkanen', Team='Chicago Bulls', Position='PF', Birthday='5/22/97', Salary=5300400),\n Row(Name='Kris Dunn', Team='Chicago Bulls', Position='PG', Birthday='3/18/94', Salary=5348007),\n Row(Name='Reggie Bullock', Team='New York Knicks', Position='SF', Birthday='3/16/91', Salary=4000000),\n Row(Name='Mike Conley', Team='Utah Jazz', Position='PG', Birthday='10/11/87', Salary=32511623),\n Row(Name='Jaylen Nowell', Team='Minnesota Timberwolves', Position='SG', Birthday='7/9/99', Salary=1400000),\n Row(Name='Gorgui Dieng', Team='Minnesota Timberwolves', Position='C', Birthday='1/18/90', Salary=16229213),\n Row(Name='Patrick Patterson', Team='Los Angeles Clippers', Position='PF', Birthday='3/14/89', Salary=3068660),\n Row(Name='Jarrett Allen', Team='Brooklyn Nets', Position='C', Birthday='4/21/98', Salary=2376840),\n Row(Name='Bobby Portis', Team='New York Knicks', Position='C', Birthday='2/10/95', Salary=15000000),\n Row(Name='Joel Embiid', Team='Philadelphia 76ers', Position='C', Birthday='3/16/94', Salary=27504630),\n Row(Name='Jonas Valanciunas', Team='Memphis Grizzlies', Position='C', Birthday='5/6/92', Salary=16000000),\n Row(Name='Chris Chiozza', Team='Washington Wizards', Position='PG', Birthday='11/21/95', Salary=79568),\n Row(Name='Kent Bazemore', Team='Portland Trail Blazers', Position='SF', Birthday='7/1/89', Salary=19269663),\n Row(Name='Tristan Thompson', Team='Cleveland Cavaliers', Position='C', Birthday='3/13/91', Salary=18539130),\n Row(Name='Mason Plumlee', Team='Denver Nuggets', Position='C', Birthday='3/5/90', Salary=14041096),\n Row(Name='Shabazz Napier', Team='Minnesota Timberwolves', Position='PG', Birthday='7/14/91', Salary=1845301),\n Row(Name='Edmond Sumner', Team='Indiana Pacers', Position='PG', Birthday='12/31/95', Salary=2000000),\n Row(Name='Alex Len', Team='Atlanta Hawks', Position='C', Birthday='6/16/93', Salary=4160000),\n Row(Name='Josh Richardson', Team='Philadelphia 76ers', Position='SF', Birthday='9/15/93', Salary=10116576),\n Row(Name='Bojan Bogdanovic', Team='Utah Jazz', Position='SF', Birthday='4/18/89', Salary=17000000),\n Row(Name='Iman Shumpert', Team='Brooklyn Nets', Position='PG', Birthday='6/26/90', Salary=2031676),\n Row(Name='Daryl Macon', Team='Miami Heat', Position='SG', Birthday='11/29/95', Salary=79568),\n Row(Name='Rodney McGruder', Team='Los Angeles Clippers', Position='SG', Birthday='7/29/91', Salary=4807693),\n Row(Name='Bam Adebayo', Team='Miami Heat', Position='C', Birthday='7/18/97', Salary=3454080),\n Row(Name='Jacob Evans', Team='Golden State Warriors', Position='SG', Birthday='6/18/97', Salary=1928280),\n Row(Name='Nigel Williams-Goss', Team='Utah Jazz', Position='PG', Birthday='9/16/94', Salary=1500000),\n Row(Name='Terrance Ferguson', Team='Oklahoma City Thunder', Position='SF', Birthday='5/17/98', Salary=2475840),\n Row(Name='Michael Carter-Williams', Team='Orlando Magic', Position='PG', Birthday='10/10/91', Salary=2028594),\n Row(Name='Bol Bol', Team='Denver Nuggets', Position='C', Birthday='11/16/99', Salary=79568),\n Row(Name='Willie Cauley-Stein', Team='Golden State Warriors', Position='C', Birthday='8/18/93', Salary=2177483),\n Row(Name='Nikola Vucevic', Team='Orlando Magic', Position='C', Birthday='10/24/90', Salary=28000000),\n Row(Name='Nicolas Batum', Team='Charlotte Hornets', Position='SF', Birthday='12/14/88', Salary=25565217),\n Row(Name='Kyrie Irving', Team='Brooklyn Nets', Position='PG', Birthday='3/23/92', Salary=31742000),\n Row(Name='Jeremy Lamb', Team='Indiana Pacers', Position='SF', Birthday='5/30/92', Salary=10500000),\n Row(Name='Donovan Mitchell', Team='Utah Jazz', Position='SG', Birthday='9/7/96', Salary=3635760),\n Row(Name='Thanasis Antetokounmpo', Team='Milwaukee Bucks', Position='SF', Birthday='7/18/92', Salary=1445697),\n Row(Name='James Johnson', Team='Miami Heat', Position='PF', Birthday='2/20/87', Salary=15349400),\n Row(Name='Monte Morris', Team='Denver Nuggets', Position='PG', Birthday='6/27/95', Salary=1588231),\n Row(Name='Terry Rozier', Team='Charlotte Hornets', Position='PG', Birthday='3/17/94', Salary=19894737),\n Row(Name='DeAndre Jordan', Team='Brooklyn Nets', Position='C', Birthday='7/21/88', Salary=9881598),\n Row(Name='Jae Crowder', Team='Memphis Grizzlies', Position='SF', Birthday='7/6/90', Salary=7815533),\n Row(Name='Josh Gray', Team='New Orleans Pelicans', Position='PG', Birthday='9/9/93', Salary=79568),\n Row(Name='Goga Bitadze', Team='Indiana Pacers', Position='C', Birthday='7/20/99', Salary=2816760),\n Row(Name='Kobi Simmons', Team='Charlotte Hornets', Position='PG', Birthday='7/4/97', Salary=79568),\n Row(Name='Derrick Favors', Team='New Orleans Pelicans', Position='C', Birthday='7/15/91', Salary=17650000),\n Row(Name='Landry Shamet', Team='Los Angeles Clippers', Position='SG', Birthday='3/13/97', Salary=1995120),\n Row(Name='Jalen McDaniels', Team='Charlotte Hornets', Position='PF', Birthday='1/31/98', Salary=898310),\n Row(Name='Bruno Caboclo', Team='Memphis Grizzlies', Position='SF', Birthday='9/21/95', Salary=1845301),\n Row(Name='Drew Eubanks', Team='San Antonio Spurs', Position='PF', Birthday='2/1/97', Salary=79568),\n Row(Name='Raul Neto', Team='Philadelphia 76ers', Position='PG', Birthday='5/19/92', Salary=1737145),\n Row(Name='Jalen Lecque', Team='Phoenix Suns', Position='G', Birthday='6/13/00', Salary=898310),\n Row(Name='Giannis Antetokounmpo', Team='Milwaukee Bucks', Position='PF', Birthday='12/6/94', Salary=25842697),\n Row(Name='Malik Monk', Team='Charlotte Hornets', Position='SG', Birthday='2/4/98', Salary=4028400),\n Row(Name='Tacko Fall', Team='Boston Celtics', Position='C', Birthday='12/10/95', Salary=79568),\n Row(Name='Justin Jackson', Team='Dallas Mavericks', Position='PF', Birthday='3/28/95', Salary=3280920),\n Row(Name='Paul George', Team='Los Angeles Clippers', Position='SF', Birthday='5/2/90', Salary=33005556),\n Row(Name='Jayson Tatum', Team='Boston Celtics', Position='PF', Birthday='3/3/98', Salary=7830000),\n Row(Name='Admiral Schofield', Team='Washington Wizards', Position='SF', Birthday='3/30/97', Salary=1000000),\n Row(Name='Louis King', Team='Detroit Pistons', Position='F', Birthday='4/6/99', Salary=79568),\n Row(Name='Kostas Antetokounmpo', Team='Los Angeles Lakers', Position='PF', Birthday='11/20/97', Salary=79568),\n Row(Name='Rodions Kurucs', Team='Brooklyn Nets', Position='PF', Birthday='2/5/98', Salary=1699236),\n Row(Name='Spencer Dinwiddie', Team='Brooklyn Nets', Position='PG', Birthday='4/6/93', Salary=10605600),\n Row(Name='Doug McDermott', Team='Indiana Pacers', Position='PF', Birthday='1/3/92', Salary=7333333),\n Row(Name='Romeo Langford', Team='Boston Celtics', Position='SG', Birthday='10/25/99', Salary=3458400),\n Row(Name='Caris LeVert', Team='Brooklyn Nets', Position='SF', Birthday='8/25/94', Salary=2625717),\n Row(Name='Michael Kidd-Gilchrist', Team='Charlotte Hornets', Position='PF', Birthday='9/26/93', Salary=13000000),\n Row(Name='LeBron James', Team='Los Angeles Lakers', Position='PF', Birthday='12/30/84', Salary=37436858),\n Row(Name='Taj Gibson', Team='New York Knicks', Position='C', Birthday='6/24/85', Salary=9000000),\n Row(Name='Ty Jerome', Team='Phoenix Suns', Position='G', Birthday='7/8/97', Salary=2193480),\n Row(Name='Chris Clemons', Team='Houston Rockets', Position='SG', Birthday='7/23/97', Salary=79568),\n Row(Name='Luke Kornet', Team='Chicago Bulls', Position='C', Birthday='7/15/95', Salary=2250000),\n Row(Name='Trey Lyles', Team='San Antonio Spurs', Position='PF', Birthday='11/5/95', Salary=5500000),\n Row(Name='Sterling Brown', Team='Milwaukee Bucks', Position='SF', Birthday='2/10/95', Salary=1618520),\n Row(Name='Andre Iguodala', Team='Memphis Grizzlies', Position='SF', Birthday='1/28/84', Salary=17185185),\n Row(Name='Vincent Poirier', Team='Boston Celtics', Position='C', Birthday='10/17/93', Salary=2505793),\n Row(Name='Frank Ntilikina', Team='New York Knicks', Position='PG', Birthday='7/28/98', Salary=4855800),\n Row(Name='Jordan McRae', Team='Washington Wizards', Position='PG', Birthday='3/28/91', Salary=1645357),\n Row(Name='Enes Kanter', Team='Boston Celtics', Position='C', Birthday='5/20/92', Salary=4767000),\n Row(Name='John Henson', Team='Cleveland Cavaliers', Position='C', Birthday='12/28/90', Salary=9732396),\n Row(Name='Jaylen Brown', Team='Boston Celtics', Position='SF', Birthday='10/24/96', Salary=6534829),\n Row(Name='Jonah Bolden', Team='Philadelphia 76ers', Position='PF', Birthday='1/2/96', Salary=1698450),\n Row(Name='Chimezie Metu', Team='San Antonio Spurs', Position='PF', Birthday='3/22/97', Salary=1416852),\n Row(Name='Tobias Harris', Team='Philadelphia 76ers', Position='PF', Birthday='7/15/92', Salary=32742000),\n Row(Name='Semi Ojeleye', Team='Boston Celtics', Position='PF', Birthday='12/5/94', Salary=1618520),\n Row(Name='Jevon Carter', Team='Phoenix Suns', Position='PG', Birthday='9/14/95', Salary=1416852),\n Row(Name='Brandon Ingram', Team='New Orleans Pelicans', Position='PF', Birthday='9/2/97', Salary=7265485),\n Row(Name='Moritz Wagner', Team='Washington Wizards', Position='C', Birthday='4/26/97', Salary=2063520),\n Row(Name='Dorian Finney-Smith', Team='Dallas Mavericks', Position='PF', Birthday='5/4/93', Salary=4000000),\n Row(Name='Danuel House', Team='Houston Rockets', Position='SF', Birthday='6/7/93', Salary=3540000),\n Row(Name='Nicolo Melli', Team='New Orleans Pelicans', Position='C', Birthday='1/26/91', Salary=4102564),\n Row(Name='Talen Horton-Tucker', Team='Los Angeles Lakers', Position='GF', Birthday='11/25/00', Salary=898310),\n Row(Name='Ed Davis', Team='Utah Jazz', Position='C', Birthday='6/5/89', Salary=4767000),\n Row(Name='Kyle Guy', Team='Sacramento Kings', Position='G', Birthday='8/11/97', Salary=79568),\n Row(Name='Kadeem Allen', Team='New York Knicks', Position='PG', Birthday='1/15/93', Salary=79568),\n Row(Name='Dante Exum', Team='Utah Jazz', Position='PG', Birthday='7/13/95', Salary=9600000),\n Row(Name='Abdel Nader', Team='Oklahoma City Thunder', Position='SF', Birthday='9/25/93', Salary=1618520),\n Row(Name='Bruno Fernando', Team='Atlanta Hawks', Position='C', Birthday='8/15/98', Salary=1400000),\n Row(Name='Dion Waiters', Team='Miami Heat', Position='SG', Birthday='12/10/91', Salary=12100000),\n Row(Name='Jared Dudley', Team='Los Angeles Lakers', Position='PF', Birthday='7/10/85', Salary=2564753),\n Row(Name='Max Strus', Team='Chicago Bulls', Position='SG', Birthday='3/28/96', Salary=79568),\n Row(Name='Kevon Looney', Team='Golden State Warriors', Position='C', Birthday='2/6/96', Salary=4464286),\n Row(Name='Willy Hernangomez', Team='Charlotte Hornets', Position='C', Birthday='5/27/94', Salary=1557250),\n Row(Name='Melvin Frazier', Team='Orlando Magic', Position='SG', Birthday='8/30/96', Salary=1416852),\n Row(Name='Austin Rivers', Team='Houston Rockets', Position='PG', Birthday='8/1/92', Salary=2174310),\n Row(Name='Harry Giles', Team='Sacramento Kings', Position='PF', Birthday='4/22/98', Salary=2578800),\n Row(Name='Robin Lopez', Team='Milwaukee Bucks', Position='C', Birthday='4/1/88', Salary=4767000),\n Row(Name='Collin Sexton', Team='Cleveland Cavaliers', Position='PG', Birthday='1/4/99', Salary=4764960),\n Row(Name='Ricky Rubio', Team='Phoenix Suns', Position='PG', Birthday='10/21/90', Salary=16200000)]\n\n\n\n\nChanging Variables \n\nAdding Columns  df.withColumn() takes the new name, along with how you’d like to create the new column. When using an already existing column, you must specify that it is a column by using col('ColumnName'). \n\n\nNote: you need to import col() in order for it to be recognized. \n\nExample: Dividing the NBA salaries by 1000\n\nfrom pyspark.sql.functions import col\ndf = df.withColumn(\"SalaryK\", col(\"Salary\")/1000)\n\n+--------------+------------------+--------+--------+-------+--------+\n|          Name|              Team|Position|Birthday| Salary| SalaryK|\n+--------------+------------------+--------+--------+-------+--------+\n|  Shake Milton|Philadelphia 76ers|      SG| 9/26/96|1445697|1445.697|\n|Christian Wood|   Detroit Pistons|      PF| 9/27/95|1645357|1645.357|\n| PJ Washington| Charlotte Hornets|      PF| 8/23/98|3831840| 3831.84|\n|  Derrick Rose|   Detroit Pistons|      PG| 10/4/88|7317074|7317.074|\n| Marial Shayok|Philadelphia 76ers|       G| 7/26/95|  79568|  79.568|\n+--------------+------------------+--------+--------+-------+--------+\nonly showing top 5 rows\n\n\n\n\nRemoving Columns  df.drop() takes one or multiple column names.  Example: Removing ‘SalaryK’\n\n\ndf = df.drop(\"SalaryK\").show(5)\n\n+--------------+------------------+--------+--------+-------+\n|          Name|              Team|Position|Birthday| Salary|\n+--------------+------------------+--------+--------+-------+\n|  Shake Milton|Philadelphia 76ers|      SG| 9/26/96|1445697|\n|Christian Wood|   Detroit Pistons|      PF| 9/27/95|1645357|\n| PJ Washington| Charlotte Hornets|      PF| 8/23/98|3831840|\n|  Derrick Rose|   Detroit Pistons|      PG| 10/4/88|7317074|\n| Marial Shayok|Philadelphia 76ers|       G| 7/26/95|  79568|\n+--------------+------------------+--------+--------+-------+\nonly showing top 5 rows\n\n\n\n\nRenaming Columns  df.withColumnRenamed() takes the current column name, followed by the new name Example: Changing ‘Birthday’ to ‘DateOfBirth’\n\n\ndf = df.withColumnRenamed(\"Birthday\", \"DateOfBirth\").show(5)\n\n+--------------+------------------+--------+-----------+-------+\n|          Name|              Team|Position|DateOfBirth| Salary|\n+--------------+------------------+--------+-----------+-------+\n|  Shake Milton|Philadelphia 76ers|      SG|    9/26/96|1445697|\n|Christian Wood|   Detroit Pistons|      PF|    9/27/95|1645357|\n| PJ Washington| Charlotte Hornets|      PF|    8/23/98|3831840|\n|  Derrick Rose|   Detroit Pistons|      PG|    10/4/88|7317074|\n| Marial Shayok|Philadelphia 76ers|       G|    7/26/95|  79568|\n+--------------+------------------+--------+-----------+-------+\nonly showing top 5 rows\n\n\n\n\nRearranging Columns Use select() to order the columns in the way that you would like.  Example:\n\n\ndf = df.select(\"Name\", \"Team\", \"Position\", \"Salary\").show(5)\n\n+--------------+------------------+--------+-------+\n|          Name|              Team|Position| Salary|\n+--------------+------------------+--------+-------+\n|  Shake Milton|Philadelphia 76ers|      SG|1445697|\n|Christian Wood|   Detroit Pistons|      PF|1645357|\n| PJ Washington| Charlotte Hornets|      PF|3831840|\n|  Derrick Rose|   Detroit Pistons|      PG|7317074|\n| Marial Shayok|Philadelphia 76ers|       G|  79568|\n+--------------+------------------+--------+-------+\nonly showing top 5 rows\n\n\n\n\n\nMathematical & Vectorized Operations \n\nAggregate Functions: \n\n\nmean() \nmin() \nmax() \nstdev_pop() \nmedian()  These functions are used within selectExpr(). They take the name of the variable you’d like to aggregate, and then add as “new_variable_name” after.  Here are the aggregation functions in action:\n\n\ndf.selectExpr(\n    \"mean(Salary) as mean_salary\",\n    \"min(Salary) as min_salary\",\n    \"max(Salary) as max_salary\",\n    \"stddev_pop(Salary) as std_salary\"\n).show()\n\n+-----------------+----------+----------+-----------------+\n|      mean_salary|min_salary|max_salary|       std_salary|\n+-----------------+----------+----------+-----------------+\n|7653583.764444444|     79568|  40231758|9278483.657952718|\n+-----------------+----------+----------+-----------------+\n\n\n\n\nUsing the functions package\n\n\nfrom pyspark.sql import functions as F\n\nThis package will allow you to create new columns or transform current ones.  Examples:  - F.avg()  - F.concat()  - F.lit()  - F.col() \nHere are these fucntions in action:\n\nsalary_mean = df.select(F.avg(\"Salary\").alias(\"mean_salary\")).collect()[0][\"mean_salary\"]\n\ndf2 = (\n    df\n    .withColumn(\"Salary_2x\", F.col(\"Salary\") * 2)    # Add Salary_2x\n    .withColumn(\n        \"Name_w_Position\",           # Concatenate Name and Position\n        F.concat(F.col(\"Name\"), F.lit(\" (\"), F.col(\"Position\"), F.lit(\")\")))\n    .withColumn(\n        \"Salary_minus_Mean\",        # Subtract mean salary\n        F.col(\"Salary\") - F.lit(salary_mean))\n).show(5)\n\n+--------------+------------------+--------+--------+-------+---------+-------------------+-------------------+\n|          Name|              Team|Position|Birthday| Salary|Salary_2x|    Name_w_Position|  Salary_minus_Mean|\n+--------------+------------------+--------+--------+-------+---------+-------------------+-------------------+\n|  Shake Milton|Philadelphia 76ers|      SG| 9/26/96|1445697|  2891394|  Shake Milton (SG)| -6207886.764444444|\n|Christian Wood|   Detroit Pistons|      PF| 9/27/95|1645357|  3290714|Christian Wood (PF)| -6008226.764444444|\n| PJ Washington| Charlotte Hornets|      PF| 8/23/98|3831840|  7663680| PJ Washington (PF)|-3821743.7644444443|\n|  Derrick Rose|   Detroit Pistons|      PG| 10/4/88|7317074| 14634148|  Derrick Rose (PG)| -336509.7644444443|\n| Marial Shayok|Philadelphia 76ers|       G| 7/26/95|  79568|   159136|  Marial Shayok (G)| -7574015.764444444|\n+--------------+------------------+--------+--------+-------+---------+-------------------+-------------------+\nonly showing top 5 rows\n\n\n\n\n\nConverting Data Types \n\n.cast() is used after a variable is specified, and takes different data types as a string. \nto_date() converts data to a specified date format. It takes the variable to be changed, and the specific date format you wish to chose.\n\n\nfrom pyspark.sql.functions import to_date\n\ndf = df.withColumn('DateOfBirth_ts', to_date('Birthday','M/d/yy')).show(5)\n\n+--------------+------------------+--------+--------+-------+--------------+\n|          Name|              Team|Position|Birthday| Salary|DateOfBirth_ts|\n+--------------+------------------+--------+--------+-------+--------------+\n|  Shake Milton|Philadelphia 76ers|      SG| 9/26/96|1445697|    2096-09-26|\n|Christian Wood|   Detroit Pistons|      PF| 9/27/95|1645357|    2095-09-27|\n| PJ Washington| Charlotte Hornets|      PF| 8/23/98|3831840|    2098-08-23|\n|  Derrick Rose|   Detroit Pistons|      PG| 10/4/88|7317074|    2088-10-04|\n| Marial Shayok|Philadelphia 76ers|       G| 7/26/95|  79568|    2095-07-26|\n+--------------+------------------+--------+--------+-------+--------------+\nonly showing top 5 rows\n\n\n\nMain Data Types:  - int  - float  - string  - boolean  - date  - timestamp \n\n\nFiltering by a Condition \ndf.filter() takes one or multiple conditions to be met and displayed. Separate conditions by putting each one in parentheses and with the & or | sign.  Here are some examples with a new DataFrame:\n\nimport pandas as pd\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()\ndf_pd = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\ndf_pd = df_pd.where(pd.notnull(df_pd), None)  # Convert NaN to None\ndf = spark.createDataFrame(df_pd)\n\n\ndf.filter(col(\"Salary\") &gt; 100000).show(5)\n\n+----------+------+----------+--------+-----+---------+\n|First Name|Gender|Start Date|  Salary| Mgmt|     Team|\n+----------+------+----------+--------+-----+---------+\n|   Douglas|  Male|    8/6/93|     NaN| true|Marketing|\n|     Maria|Female|      NULL|130590.0|false|  Finance|\n|     Jerry|  NULL|    3/4/05|138705.0| true|  Finance|\n|     Larry|  Male|   1/24/98|101004.0| true|       IT|\n|    Dennis|  Male|   4/18/87|115163.0|false|    Legal|\n+----------+------+----------+--------+-----+---------+\nonly showing top 5 rows\n\n\n\n\n#or\n\ndf.filter(\n    ( col(\"Team\") == \"Finance\" ) &\n    ( col(\"Salary\") &gt;= 100000 )\n).show(5)\n\n+----------+------+----------+--------+-----+-------+\n|First Name|Gender|Start Date|  Salary| Mgmt|   Team|\n+----------+------+----------+--------+-----+-------+\n|     Maria|Female|      NULL|130590.0|false|Finance|\n|     Jerry|  NULL|    3/4/05|138705.0| true|Finance|\n|     Bruce|  Male|  11/28/09|114796.0|false|Finance|\n|      Carl|  Male|    5/3/06|130276.0| true|Finance|\n|     Irene|  NULL|   7/14/15|100863.0| true|Finance|\n+----------+------+----------+--------+-----+-------+\nonly showing top 5 rows\n\n\n\n\n#or\n\ndf.filter(\n    (col(\"Team\") == \"Finance\") |\n    (col(\"Team\") == \"Legal\")   |\n    (col(\"Team\") == \"Sales\")\n).show(5)\n\n+----------+------+----------+--------+-----+-------+\n|First Name|Gender|Start Date|  Salary| Mgmt|   Team|\n+----------+------+----------+--------+-----+-------+\n|     Maria|Female|      NULL|130590.0|false|Finance|\n|     Jerry|  NULL|    3/4/05|138705.0| true|Finance|\n|    Dennis|  Male|   4/18/87|115163.0|false|  Legal|\n|      NULL|Female|   7/20/15| 45906.0| NULL|Finance|\n|     Julie|Female|  10/26/97|102508.0| true|  Legal|\n+----------+------+----------+--------+-----+-------+\nonly showing top 5 rows\n\n\n\nisin() used within filter(), takes a list of values within a variable and filters only those values.\n\ndf.filter(col('Team').isin('Finance','Legal','Sales')).show(5)\n\n+----------+------+----------+--------+-----+-------+\n|First Name|Gender|Start Date|  Salary| Mgmt|   Team|\n+----------+------+----------+--------+-----+-------+\n|     Maria|Female|      NULL|130590.0|false|Finance|\n|     Jerry|  NULL|    3/4/05|138705.0| true|Finance|\n|    Dennis|  Male|   4/18/87|115163.0|false|  Legal|\n|      NULL|Female|   7/20/15| 45906.0| NULL|Finance|\n|     Julie|Female|  10/26/97|102508.0| true|  Legal|\n+----------+------+----------+--------+-----+-------+\nonly showing top 5 rows\n\n\n\nbetween() is also used within filter(). It takes a range of values and returns True if a value falls wihin the range.\n\ndf_between = df.filter(col('Salary').between(90000,100000))\ndf_between.show(5)\n\n+----------+------+----------+-------+-----+-----------+\n|First Name|Gender|Start Date| Salary| Mgmt|       Team|\n+----------+------+----------+-------+-----+-----------+\n|    Angela|Female|  11/22/05|95570.0| true|Engineering|\n|    Jeremy|  Male|   9/21/10|90370.0|false|         HR|\n|    Joshua|  NULL|    3/8/12|90816.0| true|         IT|\n|      John|  Male|    7/1/92|97950.0|false|         IT|\n|     Jerry|  Male|   1/10/04|95734.0|false|         IT|\n+----------+------+----------+-------+-----+-----------+\nonly showing top 5 rows\n\n\n\n\n\nMissing Values\nFind how many missing values are in a column with isNull():\n\ndf.filter(col('Team').isNull()).count()\n\n44\n\n\nYou can find how many non-null values by using the same code and replacing isNull() with isNotNull(). \nDrop rows with missing values with na.drop():\n\ndf_drop = df.na.drop().show(10)\n\n+----------+------+----------+--------+-----+------------+\n|First Name|Gender|Start Date|  Salary| Mgmt|        Team|\n+----------+------+----------+--------+-----+------------+\n|     Larry|  Male|   1/24/98|101004.0| true|          IT|\n|    Dennis|  Male|   4/18/87|115163.0|false|       Legal|\n|      Ruby|Female|   8/17/87| 65476.0| true|     Product|\n|    Angela|Female|  11/22/05| 95570.0| true| Engineering|\n|   Frances|Female|    8/8/02|139852.0| true|Business Dev|\n|     Julie|Female|  10/26/97|102508.0| true|       Legal|\n|   Brandon|  Male|   12/1/80|112807.0| true|          HR|\n|      Gary|  Male|   1/27/08|109831.0|false|       Sales|\n|  Kimberly|Female|   1/14/99| 41426.0| true|     Finance|\n|   Lillian|Female|    6/5/16| 59414.0|false|     Product|\n+----------+------+----------+--------+-----+------------+\nonly showing top 10 rows\n\n\n\n\ntakes the argument how = 'all', which removes observations that all values are missing \nuse the argument subset = to target rows with missing values in a given variable \n\n\ndf_drop_subset = df.na.drop(subset=[\"Gender\", \"Team\"]).show(10)\n\n+----------+------+----------+--------+-----+------------+\n|First Name|Gender|Start Date|  Salary| Mgmt|        Team|\n+----------+------+----------+--------+-----+------------+\n|   Douglas|  Male|    8/6/93|     NaN| true|   Marketing|\n|     Maria|Female|      NULL|130590.0|false|     Finance|\n|     Larry|  Male|   1/24/98|101004.0| true|          IT|\n|    Dennis|  Male|   4/18/87|115163.0|false|       Legal|\n|      Ruby|Female|   8/17/87| 65476.0| true|     Product|\n|      NULL|Female|   7/20/15| 45906.0| NULL|     Finance|\n|    Angela|Female|  11/22/05| 95570.0| true| Engineering|\n|   Frances|Female|    8/8/02|139852.0| true|Business Dev|\n|     Julie|Female|  10/26/97|102508.0| true|       Legal|\n|   Brandon|  Male|   12/1/80|112807.0| true|          HR|\n+----------+------+----------+--------+-----+------------+\nonly showing top 10 rows\n\n\n\nna.fill() fills in null values with a specified value.\n\ndf_fill = df.na.fill(value = 0, subset = [\"Salary\"]).show(10)\n\n+----------+------+----------+--------+-----+------------+\n|First Name|Gender|Start Date|  Salary| Mgmt|        Team|\n+----------+------+----------+--------+-----+------------+\n|   Douglas|  Male|    8/6/93|     0.0| true|   Marketing|\n|    Thomas|  Male|   3/31/96| 61933.0| true|        NULL|\n|     Maria|Female|      NULL|130590.0|false|     Finance|\n|     Jerry|  NULL|    3/4/05|138705.0| true|     Finance|\n|     Larry|  Male|   1/24/98|101004.0| true|          IT|\n|    Dennis|  Male|   4/18/87|115163.0|false|       Legal|\n|      Ruby|Female|   8/17/87| 65476.0| true|     Product|\n|      NULL|Female|   7/20/15| 45906.0| NULL|     Finance|\n|    Angela|Female|  11/22/05| 95570.0| true| Engineering|\n|   Frances|Female|    8/8/02|139852.0| true|Business Dev|\n+----------+------+----------+--------+-----+------------+\nonly showing top 10 rows\n\n\n\n\nyou can do multiple variables at a time by usingn a dictionary instead of value = , subset =\n\n\n\nDealing with Duplicates\ndropDuplicates() drops all rows that are exact duplicates\n\ndf_no_dups = df.dropDuplicates()\n\n\nadd ['Variable_Name'] in the function to specify how to drop duplicates\n\n\ndf_no_dups_subset = df.dropDuplicates([\"Team\"])\n\nNow you’re all caught up on the PySpark basics!"
  },
  {
    "objectID": "posts/ggplot-review/ggplot-basics.html",
    "href": "posts/ggplot-review/ggplot-basics.html",
    "title": "GGPlot Basics",
    "section": "",
    "text": "Let’s go over some essentials to create amazing visualizations in GGPlot. We will use the gapminder dataframe. First, we’ll load tidyverse, which is where ggplot2 is stored, and the gapminder dataframe.\n\nlibrary(tidyverse)\nlibrary(gapminder)\ngapminder &lt;- gapminder::gapminder\nview(gapminder)\n\n\nDifferent Types of GGPlots\n\nScatter Plot\n\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point()\n\n\n\n\n\n\n\n\n1a. Scatter Plot with curve of best fit\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point()+\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nyou can get rid of the shaded part by inserting the argument se = FALSE in geom_smooth\n\n\nLine Chart\n\n\nA time series of GPD in the United States from 1952 until 2007.\n\n\ng &lt;- gapminder |&gt;\n  filter(country %in% 'United States')\n\n\nggplot(data = g,\n       mapping = aes(x = year,\n                     y = gdpPercap))+\n  geom_line()\n\n\n\n\n\n\n\n\n\nBar Chart\n\n\nThis gives a count of each continent recorded.\n\n\nggplot(data = gapminder,\n       mapping = aes(x = continent))+\n  geom_bar()\n\n\n\n\n\n\n\n\n\nBox Plot\n\n\nRange of GDP across the world in 2007\n\n\ngdp &lt;- gapminder |&gt;\n  filter(year %in% 2007)\n\n\nggplot(data = gdp,\n       mapping = aes(x = gdpPercap))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nAesthetic Mapping\nIn most cases, we will want to go beyond the basic ggPlots. We can do this in a few different ways: - add color - reduce overplotting - facets - add labels\n\nColor Color can be used to showcase different variables and/or make a graph more aesthically pleasing. Let’s add some color to our bar chart.\n\n\nggplot(data = gapminder,\n       mapping = aes(x = continent))+\n  geom_bar(aes(fill = continent))\n\n\n\n\n\n\n\n\n\nAlthough our graph is still the same, it looks much nicer and less boring than the first graph.\n\nNow, lets showcase how each continent varies in our scatter plot.\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point(aes(color = continent))\n\n\n\n\n\n\n\n\n\nThis gives us insight into how different continents compare to each other’s relationship between GDP Per Capita and Life Expectancy\n\nYou might notice that a lot of points towards the left of the graph look very crowded. This is called overplotting, and there is a way to reduce this.\n\nReduce Overplotting\n\n\nWe can use alpha to add transparency to the graph\nalpha is set to a value between 0 and 1\n\nThe closer to 0, the more transparent the points become\n\n\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point(aes(color = continent,\n                 alpha = .04))\n\n\n\n\n\n\n\n\n\nThe points are still jumbled together, but it is easier to see through the overlapping.\n\nWith a large quantity of data, sometimes it’s easier to interpret a graph if it is partitioned into smaller graphs by a variable in the dataset. This is where facets come into play.\n\nFacets Continuing with our scatter plot, separating the points into facets by continent (just like we did with color), will paint a more clear picture about the relationships between GDP and Life Expectancy for each continent.\n\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point()+\n  facet_wrap(~continent)+\n  geom_smooth()\n\n\n\n\n\n\n\n\n\nLabels\n\n\nLabels add clarity to a graph. They tell the audience exactly what they are looking at, leaving little room for misinterpretation.\n\n\nggplot(data = gapminder,\n       mapping = aes(x = gdpPercap, \n                     y = lifeExp))+\n  geom_point()+\n  facet_wrap(~continent)+\n  geom_smooth()+\nlabs(x = \"GDP Per Capita\", \n         y = \"Life Expectancy in Years\",\n         title = \"GDP and Life Expectancy Throughout the World\",\n         subtitle = \"Years 1952 Through 2007\",\n         caption = \"Source: Gapminder.\")\n\n\n\n\n\n\n\n\n-This is very useful if the variable names in a dataset are not very clear, and because you can add some background information about the data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emily Peters",
    "section": "",
    "text": "Emily Peters majors in Data Analytics and minors in Mathematics at SUNY Geneseo. Outside of school, Emily enjoys spending time outside with her dog and doing puzzles."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Emily Peters",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Data Analytics | Jan 2023 - May 2025  Minor in Business Mathematics \nGenesee Community College | Batavia, NY  Major in Economic Crime Investigation | Aug 2021 - Dec 2022"
  },
  {
    "objectID": "320_files/seaborn_basics.html",
    "href": "320_files/seaborn_basics.html",
    "title": "Seaborn Example",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample data\ndata = {\n    'Category': ['A', 'B', 'C', 'D'],\n    'Values': [23, 45, 56, 78]\n}\ndf = pd.DataFrame(data)\n\n# Create a barplot\nsns.set(style=\"whitegrid\")  # Optional: Set a clean grid style\nplt.figure(figsize=(8, 6))  # Set the figure size\nsns.barplot(data=df, x='Category', y='Values', palette='viridis')\n\n# Customize the plot\nplt.title(\"Bar Plot Example\", fontsize=16)\nplt.xlabel(\"Category\", fontsize=12)\nplt.ylabel(\"Values\", fontsize=12)\n\n# Show the plot\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(data=df, x='Category', y='Values', palette='viridis')"
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html",
    "title": "DANL 320 Project",
    "section": "",
    "text": "title: \"Assesing Credit Risk with Machine Learning\"\nauthor: \"Daniel Noone & Emily Peters\"\ndate: 2025-05-14\ncategories: ['Machine Learning', 'Project']\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nimport seaborn as sns\ncr = pd.read_csv(\"https://raw.githubusercontent.com/dannoone/dannoone.github.io/refs/heads/main/Data/credit_risk_bench.csv\")\ncr\n\n\n  \n    \n\n\n\n\n\n\nrev_util\nage\nlate_30_59\ndebt_ratio\nmonthly_inc\nopen_credit\nlate_90\nreal_estate\nlate_60_89\ndependents\ndlq_2yrs\n\n\n\n\n0\n0.006999\n38.0\n0.0\n0.302150\n5440.0\n4.0\n0.0\n1.0\n0.0\n3.0\n0\n\n\n1\n0.704592\n63.0\n0.0\n0.471441\n8000.0\n9.0\n0.0\n1.0\n0.0\n0.0\n0\n\n\n2\n0.063113\n57.0\n0.0\n0.068586\n5000.0\n17.0\n0.0\n0.0\n0.0\n0.0\n0\n\n\n3\n0.368397\n68.0\n0.0\n0.296273\n6250.0\n16.0\n0.0\n2.0\n0.0\n0.0\n0\n\n\n4\n1.000000\n34.0\n1.0\n0.000000\n3500.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16709\n1.000000\n46.0\n0.0\n170.398010\n401.0\n3.0\n2.0\n0.0\n0.0\n2.0\n1\n\n\n16710\n1.135552\n41.0\n2.0\n0.845887\n7500.0\n12.0\n0.0\n4.0\n1.0\n0.0\n1\n\n\n16711\n0.920107\n31.0\n1.0\n0.176732\n1125.0\n4.0\n1.0\n0.0\n0.0\n0.0\n1\n\n\n16712\n0.983825\n55.0\n0.0\n0.064116\n4600.0\n2.0\n1.0\n0.0\n0.0\n6.0\n1\n\n\n16713\n0.224711\n55.0\n0.0\n0.057235\n8700.0\n7.0\n0.0\n0.0\n0.0\n0.0\n1\n\n\n\n\n16714 rows × 11 columns\ncr_agg = cr\ncr_agg['total_late'] = cr_agg['late_30_59'] + cr_agg['late_60_89'] + cr_agg['late_90']\n\ncr_agg = cr_agg.drop(columns = ['late_30_59','late_60_89','late_90'])\n\ncr_agg\n\n\n  \n    \n\n\n\n\n\n\nrev_util\nage\ndebt_ratio\nmonthly_inc\nopen_credit\nreal_estate\ndependents\ndlq_2yrs\ntotal_late\n\n\n\n\n0\n0.006999\n38.0\n0.302150\n5440.0\n4.0\n1.0\n3.0\n0\n0.0\n\n\n1\n0.704592\n63.0\n0.471441\n8000.0\n9.0\n1.0\n0.0\n0\n0.0\n\n\n2\n0.063113\n57.0\n0.068586\n5000.0\n17.0\n0.0\n0.0\n0\n0.0\n\n\n3\n0.368397\n68.0\n0.296273\n6250.0\n16.0\n2.0\n0.0\n0\n0.0\n\n\n4\n1.000000\n34.0\n0.000000\n3500.0\n0.0\n0.0\n1.0\n0\n1.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n16709\n1.000000\n46.0\n170.398010\n401.0\n3.0\n0.0\n2.0\n1\n2.0\n\n\n16710\n1.135552\n41.0\n0.845887\n7500.0\n12.0\n4.0\n0.0\n1\n3.0\n\n\n16711\n0.920107\n31.0\n0.176732\n1125.0\n4.0\n0.0\n0.0\n1\n2.0\n\n\n16712\n0.983825\n55.0\n0.064116\n4600.0\n2.0\n0.0\n6.0\n1\n1.0\n\n\n16713\n0.224711\n55.0\n0.057235\n8700.0\n7.0\n0.0\n0.0\n1\n0.0\n\n\n\n\n16714 rows × 9 columns"
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#background",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#background",
    "title": "DANL 320 Project",
    "section": "Background",
    "text": "Background\nAnalyzing credit risk involves determining if a certain borrower will be able to pay off a loan or credit line within the expected time. Banks cannot just simply hand out loans to whoever needs one because it is not guaranteed that the borrower will pay it back. As consumers, we want our banks making very informed decisions, backed by data, on who to give out loans to since we depend on them to handle our money. For banks, identifying borrowers who will potentially commit delinquency allows them to set different interest rates for this type of borrower or even deny the loan altogether which leaves more money for loans that are less risky, potentially increases profits, and therefore helps the bank remain financially stable. With machine learning technologies that are always improving paired with the constant collection of data, banks can use this to their advantage when making tough decisions about loan approvals."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#problem",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#problem",
    "title": "DANL 320 Project",
    "section": "Problem",
    "text": "Problem\nGiving out loans that can’t be paid back need to be minimized, but qualifications shouldn’t be so strict that it makes getting a loan extremely difficult for financially responsible borrowers. Banks need to find the right balance so they’re not losing money, but they’re not turning away good customers either."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#objective",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#objective",
    "title": "DANL 320 Project",
    "section": "Objective",
    "text": "Objective\nThe goal of this project is to execute machine learning models that can predict if a borrower will be able to repay a loan on time based on the borrower’s financial history. These models should be able to accurately find the differences between borrowers who make payments on time and those who do not, so banks can make sound lending decisions."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#variables",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#variables",
    "title": "DANL 320 Project",
    "section": "Variables",
    "text": "Variables"
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#data-cleaning-and-processing",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#data-cleaning-and-processing",
    "title": "DANL 320 Project",
    "section": "Data Cleaning and Processing",
    "text": "Data Cleaning and Processing\nTo omit the effect of outliers within the late_* variables, the total_late variable was created to account for all late payments per borrower. This is further explained in the next section under Investigation of Perfect Correlation Among late_* Variables."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#correlation-heat-map",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#correlation-heat-map",
    "title": "DANL 320 Project",
    "section": "Correlation Heat Map",
    "text": "Correlation Heat Map\n\ndf_corr = cr.copy()\n# Compute correlation matrix\ncorr_matrix = df_corr.corr()\n\n# 3. Correlation heatmap using matplotlib\nfig, ax = plt.subplots(figsize=(12, 10))\ncax = ax.imshow(corr_matrix.values, aspect='auto')\nfig.colorbar(cax, ax=ax)\nax.set_xticks(range(len(corr_matrix.columns)))\nax.set_yticks(range(len(corr_matrix.columns)))\nax.set_xticklabels(corr_matrix.columns, rotation=90, fontsize=6)\nax.set_yticklabels(corr_matrix.columns, fontsize=6)\nplt.title('How Are Variables Correlated?')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nSurprisingly, the three late_* variables are all perfectly correlated. These variables could have such a high correlation because they are each counting the same thing, just in a different time period. It makes sense that a borrower who has fallen behind on a payment will continue to fall behind and make even later payments. This will be investigated further in the next section to determine the true cause. Also, it is important to note that the real_estate and open_credit variables have a strong, positive correlation. This seems correct, as they are both lines of credit, and it is common for an individual to have these different lines simultaneously."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#investigation-of-perfect-correlations-among-late_-variables",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#investigation-of-perfect-correlations-among-late_-variables",
    "title": "DANL 320 Project",
    "section": "Investigation of Perfect Correlations Among late_* Variables",
    "text": "Investigation of Perfect Correlations Among late_* Variables\n\nplt.subplot(1,2,1)\nsns.regplot(data = cr, x = 'late_30_59', y = 'late_60_89')\n\nplt.subplot(1,2,2)\nsns.regplot(data = cr, x = 'late_60_89', y = 'late_90')\nplt.show()\n\n\n\n\n\n\n\n\n\n# filtering outliers\ncr_filter = cr[(cr['late_30_59'] &lt; 60) & (cr['late_60_89'] &lt; 60) & (cr['late_90'] &lt; 60)]\n\n\nplt.subplot(1,2,1)\nsns.regplot(data = cr_filter, x = 'late_30_59', y = 'late_60_89')\n\nplt.subplot(1,2,2)\nsns.regplot(data = cr_filter, x = 'late_60_89', y = 'late_90')\nplt.show()\n\n\n\n\n\n\n\n\nThe perfect correlations were being caused by extreme outliers in each late_* variable. After filtering out these values, you can see a more accurate representation of the relationships between these variables. It is now clear that the points are more scattered. The variables have positive relationships, but they are far from perfect. As briefly mentioned before, a new variable was created to replace these three late_* variables to help decrease bias in our machine learning models. The new variable, total_late, includes the sum of all late payments made by each borrower."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#age-distribution",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#age-distribution",
    "title": "DANL 320 Project",
    "section": "Age Distribution",
    "text": "Age Distribution\n\nsns.histplot(data = cr, x = 'age', bins = 10)\n\n\n\n\n\n\n\n\nTo get a better idea of the borrowers in these data, here is the distribution of age. As you can see, most of the borrowers are between the ages of about 37 and 61. The dataset is slightly skewed, as there are some older borrowers included as well, between the ages of about 77 and 101."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#refining-random-forest-model",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#refining-random-forest-model",
    "title": "DANL 320 Project",
    "section": "Refining Random Forest Model",
    "text": "Refining Random Forest Model\n\n# Define the grid of hyperparameters:\n# - min_samples_leaf is the minimum number of samples in a terminal node.\nparam_grid = {\n    \"max_features\": list(range(3, 15, 2)),\n    \"min_samples_leaf\": [5]\n}\n\n# Initialize the RandomForestRegressor:\n# - n_estimators is set to 50 (equivalent to num.trees)\n# - random_state is set for reproducibility.\n# rf = RandomForestRegressor(n_estimators=50, random_state=1917)\n\nrf = RandomForestRegressor(n_estimators=500,  # Number of trees in the forest\n                           random_state=42,\n                           oob_score=True)    # Use out-of-bag samples to estimate error\n\n# Set up 10-fold cross-validation and GridSearch over the parameters\ngrid_search = GridSearchCV(\n    estimator=rf,\n    param_grid=param_grid,\n    cv=10,\n    scoring=\"neg_mean_squared_error\",\n    return_train_score=True,\n    n_jobs=-1,\n    verbose=1\n)\n\n# Fit the grid search on the data\ngrid_search.fit(X_train, y_train.ravel())\n\n# Extract the best parameters\nprint(\"Best Parameters:\", grid_search.best_params_)\n\n# To replicate the ggplot visualization from R, we plot the grid search results.\nresults = pd.DataFrame(grid_search.cv_results_)\n\nplt.figure(figsize=(8, 6))\nplt.errorbar(\n    results[\"param_max_features\"].astype(int),\n    -results[\"mean_test_score\"],\n    yerr=results[\"std_test_score\"],\n    fmt=\"o-\",\n    capsize=5\n)\nplt.title(\"Grid Search CV Results\")\nplt.xlabel(\"max_features (mtry equivalent)\")\nplt.ylabel(\"Mean Squared Error\")\nplt.grid(True)\nplt.show()\n\nFitting 10 folds for each of 6 candidates, totalling 60 fits\nBest Parameters: {'max_features': 3, 'min_samples_leaf': 5}\n\n\n\n\n\n\n\n\n\nThe model performed well on the training data since the training MSE is very low, but this model could use some further refining as the test MSE is slightly larger, suggesting some overfitting. The out-of-bag score indicates that 34.74% of the out-of-bag sample was predicted correctly, which is not very high. After setting up and fitting a Grid Search on the training data, it was concluded that the optimal max_features is 3. When the max_features are set to 3, the test MSE is the lowest compared to other max_feature values. Through refining the Random Forest model, we are able to find the most important variables, rev_utils and total_late, which slightly differ from the biggest weights assigned by the previous logistic regression model."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#pca-and-cluster-analysis",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#pca-and-cluster-analysis",
    "title": "DANL 320 Project",
    "section": "PCA and Cluster Analysis",
    "text": "PCA and Cluster Analysis\n\nfeatures = ['rev_util', 'total_late','debt_ratio', 'open_credit', 'real_estate','dependents', 'dlq_2yrs']\ncr = cr_agg\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(cr[features])\n\n\npca = PCA()\nX_pca = pca.fit_transform(X_scaled)\n\n\nScree Plot\n\nplt.figure(figsize=(8, 4))\nplt.plot(range(1, len(features) + 1), pca.explained_variance_ratio_, marker='o')\nplt.title('Scree Plot')\nplt.xlabel('Principal Component')\nplt.ylabel('Variance Explained')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\nThe scree plot for our PCA analysis shows that ~38% of the total variance is explained by the first two principal components.\n\n\n\nCluster Analysis\n\npca_2 = PCA(n_components=2)\nX_pca_2 = pca_2.fit_transform(X_scaled)\n\n\nkmeans = KMeans(n_clusters=3, random_state=42)\nclusters = kmeans.fit_predict(X_pca_2)\n\n\ncr['cluster'] = clusters\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(x=X_pca_2[:, 0], y=X_pca_2[:, 1], hue=cr['cluster'], palette='Set2')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.title('Cluster Plot on First Two Principal Components')\nplt.grid(True)\nplt.show()\n\nC:\\Users\\noone\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n[WinError 2] The system cannot find the file specified\nReturning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n  warnings.warn(\n  File \"C:\\Users\\noone\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n    cpu_info = subprocess.run(\n               ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\noone\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n    with Popen(*popenargs, **kwargs) as process:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\noone\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Users\\noone\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n\n\n\n\n\n\n\n\nThis is a visualization of the KMeans clustering with the first two principal components. There can be seen three distinct clusters which have very distinct boundaries between them. Cluster 0 which is green, is small when compared to the other two and has seemingly fewer outliers. Cluster 1 which is orange is grouped very tightly for the most part. Finally, cluster 2 which is purple is much larger than the other two and is more widespread.\n\n\nOverall:  - This visualization suggests that there exist meaningful groupings within the credit risk data set."
  },
  {
    "objectID": "320_files/danl_320_noone_daniel_peters_emily_project.html#multi-layer-perceptron-for-binary-classification",
    "href": "320_files/danl_320_noone_daniel_peters_emily_project.html#multi-layer-perceptron-for-binary-classification",
    "title": "DANL 320 Project",
    "section": "Multi-Layer Perceptron for Binary Classification",
    "text": "Multi-Layer Perceptron for Binary Classification\nA multi-layer perceptron (MLP) for binary classsification is a form of neural network that takes the role of a classifier deciding between two classes. In this case it is deciding essentially if an individual is risky to lend to or not. The method by which this model was built was by defining multiple user-defined funtions (UDFs) which were then combined into one final training loop. This next section will focus on going over the individual UDFs and how they combine into the final training loop, along with UDFs for performance calculation and predictions. This specific set of UDFs is ONLY for networks with two hidden layers.\n\n&gt; initialize_params\n\ndef initialize_params(X, num_units_hidden_1, num_units_hidden_2, ): # He Initialization due to ReLU type activation.\n  scale1 = np.sqrt(2 / X.shape[1])\n  W1 = np.random.randn(X.shape[1], num_units_hidden_1) * scale1\n\n  scale2 = np.sqrt(2 / num_units_hidden_1)\n  W2 = np.random.randn(num_units_hidden_1, num_units_hidden_2) * scale2\n\n  scale3 = np.sqrt(2 / num_units_hidden_2)\n  W3 = np.random.randn(num_units_hidden_2, 1) * scale3\n\n  b1 = np.zeros((1, num_units_hidden_1))\n  b2 = np.zeros((1, num_units_hidden_2))\n  b3 = np.zeros((1,1))\n\n  params = {\n      'W1': W1,\n      'W2': W2,\n      'W3': W3,\n      'b1': b1,\n      'b2': b2,\n      'b3': b3\n  }\n\n  return params\n\nSize of Parameter Matrices the initialize_params UDF takes a matrix X with shape (m,n) - where m = number of training examples, and n = number of features along with num_units_hidden_1 and num_units_hidden_2 which are integer values describing how many neurons are in each hidden layer. The purpose is to initialize weights and biases for the specific arcitecture needed, and determined by the inputs of the UDF.\nIn our specific case X has 8 features, 64 neuarons in HL1, and 32 neurons in HL2. So the resulting shapes are as follows:\n- W1 : (8,64)     - b1 : (1,64)\n- W2 : (64,32)    - b2 : (1,32)\n- W3 : (34,1)     - b3 : (1,1)\nWeights - He Initialization The weights are random values from a standard normal distribution (np.random.randn()) and scaled using He Initialization which is an appropriate parameter initialization metod for ReLU type activation functions (Leaky ReLU in our case). The goal of using He Initialization is to avoid vanishing or exploding gradients which would lead to slowed/failed training.\n\n### \\(scale_i = \\sqrt{\\frac{2}{n}}\\) Where: n = number of features into layer i\n\nThus, He Initialization here attempts to keep outputs stable across layers when using ReLU type activation functions by multiplying \\(Wi\\) by \\(scale_i\\).\nBiases Biases are simply initialized to zeros\nPackaging for Future Use The Weights and Biases are then packaged in a dictionary which is the output of the initialize_params UDF.\n\n\n&gt; sigmoid, leaky_relu, and forward_prop\n\ndef sigmoid(X):\n  X = np.clip(X, -500, 500) # To prevent overflow\n  g = 1 / (1 + np.exp(-X))\n  return g\n\ndef leaky_relu(X, alpha_rel):\n  return np.where(X &gt; 0, X, alpha_rel * X)\n\ndef forward_prop(X, params, alpha_rel): # With Leaky ReLU Activation (np.max(alpha*Z,Z))\n  W1 = params['W1']\n  W2 = params['W2']\n  W3 = params['W3']\n\n  b1 = params['b1']\n  b2 = params['b2']\n  b3 = params['b3']\n\n  # Hidden 1\n  Z1 = np.dot(X, W1) + b1\n  A1 = leaky_relu(Z1, alpha_rel)\n\n  # Hidden 2\n  Z2 = np.dot(A1, W2) + b2\n  A2 = leaky_relu(Z2, alpha_rel)\n\n  # Output\n  Z3 = np.dot(A2, W3) + b3\n  A3 = sigmoid(Z3)\n\n  cache = {\n      'Z1': Z1,\n      'A1': A1,\n      'Z2': Z2,\n      'A2': A2,\n      'Z3': Z3,\n      'A3': A3\n  }\n\n  return cache\n\nSigmoid * To be used in the forward_prop UDF in the output layer to transform pre-activation \\(Z^{[3]}\\) into probabilites in post-activation \\(A^{[3]}\\) * Takes as inputs: * X: The pre-activation values of the output layer in the MLP. \\[ g(x) = \\frac{1}{1 + e^{-x}}\\]\n\nReturns the probability that the prediction is 1  Leaky ReLU * The chosen activation function, which scales values that are less than 0 by a chosen \\(\\alpha\\), to be used in the forward_prop UDF. * Takes as inputs: * X: The pre-activations of the given layer * alpha_rel: Chosen value for \\(\\alpha\\) \\[\n\\text{LeakyReLU}(x) =\n\\begin{cases}\nx, & \\text{if } x \\geq 0 \\\\\n\\alpha x, & \\text{if } x &lt; 0\n\\end{cases}\n\\]  Forward Propagation * The full forward pass function for the 2 hidden layer MLP. * Takes as inputs: * X: Input data of size m x n * params: Dictionary of parameters originally obtained from initialize_params * alpha_rel: Chosen value for \\(\\alpha\\) in Leaky ReLU * Loads in the parameters from params and calculates the pre-/post-activations for each layer using Leaky ReLU to find post activations until the output layer while the UDF for sigmoid is used to calculate the probabilized output.\n\n\nA Look at the forward pass \\(Z_1 = X \\cdot W_1 + b_1  \\rightarrow\\rightarrow\\rightarrow A_1 = \\text{LeakyReLU}(Z_1)\\) \\(Z_2 = A_1 \\cdot W_2 + b_2  \\rightarrow\\rightarrow\\rightarrow A_2 = \\text{LeakyReLU}(Z_2)\\) \\(Z_3 = A_2 \\cdot W_3 + b_3  \\rightarrow\\rightarrow\\rightarrow A_3 = \\text{Sigmoid}(Z_3) = \\hat{y}\\)\n\n\nFinally, all of the intermediates are stored in a dictionary labeled cache which is returned by the UDF.\n\n\n\nbinary_cross_entropy\n\ndef binary_cross_entropy(y, cache):\n  m,n = y.shape\n  epsilon = 1e-12  # To avoid log(0)\n  y_hat = np.clip(cache['A3'], epsilon, 1 - epsilon) # To avoid log(0) errors\n  bce = -((y*np.log(y_hat)) + ((1-y)*np.log(1-y_hat)))\n  cost = np.sum(bce) / m\n\n  return cost\n\nUsed to calculate the cost function \\(\\mathcal{J}(W,b)\\) which is the loss function \\(\\mathcal{L}(y,\\hat{y})\\) averaged over all training examples \\(m\\). * Takes as inputs: * y: The true label data stored in an m x 1 matrix * cache: Results of forward_prop UDF storing intermediates and probabilities in a dictionary\n\n\\(\\epsilon\\) is defined to be used in the np.clip() of the probabilites \\(A_3\\), so as to avoid \\(\\log{(0)}\\) errors.\nBinary cross entropy is then calculated…\n\n\\(\\mathcal{L} = -\\left( y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) \\right)\\)\n\nThen averaged over \\(m\\) training examples\n\n\\(J = \\frac{1}{m} \\sum_{i=1}^{m} \\mathcal{L}^{(i)}\\)\n\nCost is then returned by the UDF.\n\n\n\nleaky_relu_dv, back_prop, and update_params\n\ndef leaky_relu_dv(X, alpha_rel):\n  return np.where(X &gt; 0, 1, alpha_rel)\n\ndef back_prop(X, y, params, cache, alpha_rel):\n  W1 = params['W1']\n  W2 = params['W2']\n  W3 = params['W3']\n  b1 = params['b1']\n  b2 = params['b2']\n  b3 = params['b3']\n  Z1 = cache['Z1']\n  Z2 = cache['Z2']\n  Z3 = cache['Z3']\n  A1 = cache['A1']\n  A2 = cache['A2']\n  A3 = cache['A3']\n\n  m,n = X.shape\n\n  # Output\n  dZ3 = A3 - y\n  dW3 = np.dot(A2.T, dZ3) /m\n  db3 = np.sum(dZ3, axis = 0, keepdims = True) /m\n\n  # Hidden 2\n  dA2 = np.dot(dZ3, W3.T)\n  dZ2 = dA2 * leaky_relu_dv(Z2, alpha_rel)\n  dW2 = np.dot(A1.T, dZ2) /m\n  db2 = np.sum(dZ2, axis = 0, keepdims = True) /m\n\n  # Hidden 1\n  dA1 = np.dot(dZ2, W2.T)\n  dZ1 = dA1 * leaky_relu_dv(Z1, alpha_rel)\n  dW1 = np.dot(X.T, dZ1) /m\n  db1 = np.sum(dZ1, axis = 0, keepdims = True) /m\n\n  gradients = {\n      'dW3': dW3,\n      'dW2': dW2,\n      'dW1': dW1,\n      'db3': db3,\n      'db2': db2,\n      'db1': db1\n  }\n\n  return gradients\n\ndef update_params(params, gradients, alpha, clip, clip_value):\n\n  if clip == True:\n    gradients['dW1'] = np.clip(gradients['dW1'], -clip_value, clip_value) # Gradient clipping to avoid exploding gradients\n    gradients['dW2'] = np.clip(gradients['dW2'], -clip_value, clip_value)\n    gradients['dW3'] = np.clip(gradients['dW3'], -clip_value, clip_value)\n    gradients['db1'] = np.clip(gradients['db1'], -clip_value, clip_value)\n    gradients['db2'] = np.clip(gradients['db2'], -clip_value, clip_value)\n    gradients['db3'] = np.clip(gradients['db3'], -clip_value, clip_value)\n\n\n  params['W1'] -= gradients['dW1'] * alpha\n  params['W2'] -= gradients['dW2'] * alpha\n  params['W3'] -= gradients['dW3'] * alpha\n\n  params['b1'] -= gradients['db1'] * alpha\n  params['b2'] -= gradients['db2'] * alpha\n  params['b3'] -= gradients['db3'] * alpha\n\n\n\n  return params\n\nGradient, Leaky ReLU * To be used in the back_prop UDF to calculate the derivative of the Leaky ReLU activation function w.r.t its input. * Takes as inputs: * X: Again, the pre-activation value of the layer * alpha_rel: The chosen \\(\\alpha\\) for Leaky ReLU\n\\[\n\\text{LeakyReLU}'(x) =\n\\begin{cases}\n1, & \\text{if } x \\geq 0 \\\\\n\\alpha, & \\text{if } x &lt; 0\n\\end{cases}\n\\] ____ Backpropagation * Calculates the gradients of \\(\\mathcal{J}(W,b)\\) w.r.t. the Weights and biases to be used in updating the parameters. * Takes as inputs: * X: Input data of size m x n * y: True label data * params: Dictionary of parameters * cache: Dictionary of intermediates and output * alpha_rel: Chosen \\(\\alpha\\) for Leaky ReLU * Loads in parameters from params and intermediates/output from cache and uses them to perform backpropagation to find the gradients.\n\nA look at the backpropagation _________________________________________________________________________________________________________________________________ Output Layer - \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{Z_3}} = A_3 - y\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{W_3}} =  \\frac{A_2^\\top \\cdot \\frac{\\partial\\mathcal{J}}{\\partial{Z_3}}}{m}\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{b_3}} =  \\frac{\\sum_{i=1}^{m}\\frac{\\partial\\mathcal{J}}{\\partial{Z_3^{(i)}}}}{m}\n\\] HL2 - \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{A_2}} =  \\frac{\\partial\\mathcal{J}}{\\partial{Z_3}}  \\cdot W_3^\\top\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{Z_2}} =  \\frac{\\partial\\mathcal{J}}{\\partial{A_2}} \\cdot LeakyReLU'(Z_2)\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{W_2}} =  \\frac{A_1^\\top \\cdot \\frac{\\partial\\mathcal{J}}{\\partial{Z_2}}}{m}\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{b_2}} =  \\frac{\\sum_{i=1}^{m}\\frac{\\partial\\mathcal{J}}{\\partial{Z_2^{(i)}}}}{m}\n\\] HL1 - \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{A_1}} =  \\frac{\\partial\\mathcal{J}}{\\partial{Z_2}}  \\cdot W_2^\\top\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{Z_1}} =  \\frac{\\partial\\mathcal{J}}{\\partial{A_1}} \\cdot LeakyReLU'(Z_1)\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{W_1}} =  \\frac{X^\\top \\cdot \\frac{\\partial\\mathcal{J}}{\\partial{Z_1}}}{m}\n\\] \\[\n\\frac{\\partial\\mathcal{J}}{\\partial{b_1}} =  \\frac{\\sum_{i=1}^{m}\\frac{\\partial\\mathcal{J}}{\\partial{Z_1^{(i)}}}}{m}\n\\] _________________________________________________________________________________________________________________________________ * Gradients are then stored in a dictionary gradients which is returned for future use ____ Updating Parameters - Updates the parameters using gradients calculated with back_prop UDF, and provides the option to clip the gradients if needed. - Takes as inputs: - params: Dictionary with the parameters - gradients: Dictionary with gradients from the back_prop UDF - alpha: Chosen learning rate \\(\\alpha\\) - clip: True or False, if clip ==True the UDF will clip the gradients - clip_value: If clip == True the gradients will be clipped by the value of clip_value\n\n\nBasic formula: \\[\nP_{new} = P_{old} - \\alpha \\frac{\\partial \\mathcal{J}}{\\partial P_i}\n\\]\n\n\nThe parameters in the params dictionary are updated with these new adjusted parameters which is what the UDF returns.\n\n\n\ntraining_loop\n\ndef training_loop(X, y, alpha, alpha_rel, epochs, clip, clip_value, num_units_hidden_1, num_units_hidden_2):\n  cost_hist = []\n  iter_hist = []\n  dw3_hist = []\n  dw2_hist = []\n  dw1_hist = []\n  db3_hist = []\n  db2_hist = []\n  db1_hist = []\n  params = initialize_params(X, num_units_hidden_1, num_units_hidden_2)\n\n  for i in range(epochs):\n    iter_hist.append(i)\n    cache = forward_prop(X, params, alpha_rel)\n    cost = binary_cross_entropy(y, cache)\n    cost_hist.append(cost)\n    gradients = back_prop(X, y, params, cache, alpha_rel)\n    params = update_params(params, gradients, alpha, clip, clip_value)\n\n    dw3_hist.append(gradients['dW3'])\n    dw2_hist.append(gradients['dW2'])\n    dw1_hist.append(gradients['dW1'])\n    db3_hist.append(gradients['db3'])\n    db2_hist.append(gradients['db2'])\n    db1_hist.append(gradients['db1'])\n\n    if i % 50 == 0:\n      print(f'Epoch: {i}/{epochs} --- --- --- Cost: {cost}')\n      print('Max dW3:', float(np.max(np.abs(gradients['dW3']))))\n      print('Mean A2 &gt; 0:', np.mean(cache['A2'] &gt; 0))\n      print('----------------------------------------------')\n\n  gradient_history = {\n      'dW3': dw3_hist,\n      'dW2': dw2_hist,\n      'dW1': dw1_hist,\n      'db3': db3_hist,\n      'db2': db2_hist,\n      'db1': db1_hist,\n  }\n\n  return cost_hist, iter_hist, params, cache, gradients, gradient_history # Returns raw sigmoid output in cache['A3']\n\n\nFull training loop for the MLP.\nPerforms the forward pass, computes loss/cost, finds the gradients with backpropagation and updates the parameters for a set number of epochs/iterations\nTakes as inputs:\n\nX: Training data\ny: Label data\nalpha: Learning rate\nalpha_rel: Alpha for LeakyReLU\nepochs: number of epochs/iterations to run for\nclip: Decide whether or not to clip\nclip_value: Clip by this much\nnum_units_hidden_1: Number of units in hidden layer 1\nnum_units_hidden_2: number of units in hidden layer 2\n\nGeneral Process\n\nSets up empty lists to track metrics and gradients\n\nParameters are initialized using initialize_params\nFor range of epochs:\n\nPerform forward pass with forward_prop\nUse results from forward_prop to calculate cost using binary_cross_entropy\nGradients are calculated using back_prop\nParameters are updated using gradients and learning rate \\(\\alpha\\) using update_params\n\n\n\nReturns:\n\nCost History\nIterations\nParameter Dictionary\nCache Dictionary\nGradient Dictionary\nGradient History Dictionary\n\n\n\n\npredict, metrics_compute, and to_binary\n\ndef to_binary(y, threshold):\n  return (y &gt; threshold).astype(int)\n\ndef predict(X, params, threshold, alpha_rel):\n  cache = forward_prop(X, params, alpha_rel)\n  y_pred = cache['A3']\n  y_pred_bin = to_binary(y_pred, threshold)\n  return y_pred, y_pred_bin\n\ndef metrics_compute(y_hat, y):\n  TP = np.sum((y == 1) & (y_hat == 1))\n  FP = np.sum((y == 0) & (y_hat == 1))\n  FN = np.sum((y == 1) & (y_hat == 0))\n  TN = np.sum((y == 0) & (y_hat == 0))\n\n\n  print('+------ Confusion Matrix ------+')\n  print(f'   {TN}                {FP} ')\n  print('|------------------------------|')\n  print(f'   {FN}                {TP}')\n  print('+------------------------------+')\n\n  accuracy = (TP + TN) / (TP + TN + FP + FN)\n  precision = TP / (TP + FP)\n  recall = TP / (TP + FN)\n  f1 = (2 * precision * recall) / (precision + recall)\n\n  metrics = {\n      'TP': TP,\n      'TN': TN,\n      'FP': FP,\n      'FN': FN,\n      'accuracy': accuracy,\n      'precision': precision,\n      'recall': recall,\n      'f1': f1\n  }\n\n\n  print(f'Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nf1-score: {f1}')\n\n  return metrics\n\nBinary - UDF simply takes the input and sets it to 1 if greater than threshold, or to 0 if less than threshold\nPredict - This UDF performs a forward pass with forward_prop and returns the probabilities and binarized output.\nMetrics - Calculates many of the metrics necessary to assess a binary classifier. - Calculates metrics and prints out a confusion matrix - Calculates accuracy, precision, recall, and f1-score which is also printed - It returns a dictionary with all of these metrics stored\n\n\nResults\n\n\nBelow is the confusion matrix for our MLP with a chosen threshold of 0.2, looking into the future it would be beneficial to better tune a proper threshold\n\n\n+------ Confusion Matrix ------+\n   460                1622\n|------------------------------|\n   194                1903\n+------------------------------+\nAccuracy: 0.5654462790141183\nPrecision: 0.5398581560283688\nRecall: 0.9074868860276586\nf1-score: 0.6769832799715404\n\n\n\nIt can be seen that accuracy and precision measures are very poor and not much better than random chance.\nRecall on the other hand is too high at ~90.7%\nThe f1-score is okay at ~67.7%\n\nWhat this means: - The model performs too far one way, it shows too much affinity for predicting that someone will be a risky borrower - This is beneficial if the goal here is to avoid risk at all costs, but in most cases this would be considered poor performance because as much as risk is good to avoid, too many unrisky borrowers were deemed risky.\nWhat could be done better? - There could be more time spent exploring different architectures such as different numbers of neurons per layer, more or less hidden layers, threshold optimization, different activation functions, and better tuning of hyperparameters such as the learning rate and epochs. - Doing these things could lead to a very good model that is proficient in predicting credit risk"
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html",
    "href": "310_files/danl-310-quarto-r.html",
    "title": "Quarto with R",
    "section": "",
    "text": "“Tidy datasets are all alike, but every messy dataset is messy in its own way.” — Hadley Wickham\n\nR is a powerful language and environment for statistical computing and graphics. It is widely used among statisticians and data analysts for data analysis and developing statistical software. Here are some basic concepts and elements of R to help you get started:\n\n\n\nVariables in R are used to store data. You can create a variable using the assignment operator &lt;- (option/Alt + -). For example:\n\n\nCode\nmy_variable &lt;- 10\n\n\nThis will store the value 10 in my_variable.\n\n\n\n\n\nR has several basic data types:\n\nNumeric: For decimal values like 2.5.\nInteger: For whole numbers like 2L (the L tells R it is an integer).\nCharacter: For text or string values, e.g., \"Hello\".\nLogical: For boolean values (TRUE or FALSE).\n\n\n\n\n\n\nVectors are a basic data structure in R. They contain elements of the same type. You can create a vector using the c() function:\n\n\nCode\nmy_vector &lt;- c(1, 2, 3, 4, 5)\n\n\n\n\n\n\nData frames are used for storing data tables in R. It is a list of vectors of equal length. For example, to create a simple data frame:\n\n\nCode\ndf &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\"), \n  Age = c(25, 30)\n  )\n\n\n\n\n\n\nFunctions are used to carry out specific tasks in R. For example, sum() is a function that adds numbers together:\n\n\nCode\nsum(1, 2, 3) # Returns 6\n\n\n[1] 6\n\n\n\n\n\n\nR has a vast collection of packages for various statistical tasks. You can install a package using install.packages(\"packageName\") and load it using library(packageName).\n\n\nCode\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\n\n\n\n\n\nTo get help on a specific function or topic, use the help() function or the shorthand ?, like ?sum on R Console."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#variables",
    "href": "310_files/danl-310-quarto-r.html#variables",
    "title": "Quarto with R",
    "section": "",
    "text": "Variables in R are used to store data. You can create a variable using the assignment operator &lt;- (option/Alt + -). For example:\n\n\nCode\nmy_variable &lt;- 10\n\n\nThis will store the value 10 in my_variable."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#data-types",
    "href": "310_files/danl-310-quarto-r.html#data-types",
    "title": "Quarto with R",
    "section": "",
    "text": "R has several basic data types:\n\nNumeric: For decimal values like 2.5.\nInteger: For whole numbers like 2L (the L tells R it is an integer).\nCharacter: For text or string values, e.g., \"Hello\".\nLogical: For boolean values (TRUE or FALSE)."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#vectors",
    "href": "310_files/danl-310-quarto-r.html#vectors",
    "title": "Quarto with R",
    "section": "",
    "text": "Vectors are a basic data structure in R. They contain elements of the same type. You can create a vector using the c() function:\n\n\nCode\nmy_vector &lt;- c(1, 2, 3, 4, 5)"
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#data-frames",
    "href": "310_files/danl-310-quarto-r.html#data-frames",
    "title": "Quarto with R",
    "section": "",
    "text": "Data frames are used for storing data tables in R. It is a list of vectors of equal length. For example, to create a simple data frame:\n\n\nCode\ndf &lt;- data.frame(\n  Name = c(\"Alice\", \"Bob\"), \n  Age = c(25, 30)\n  )"
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#functions",
    "href": "310_files/danl-310-quarto-r.html#functions",
    "title": "Quarto with R",
    "section": "",
    "text": "Functions are used to carry out specific tasks in R. For example, sum() is a function that adds numbers together:\n\n\nCode\nsum(1, 2, 3) # Returns 6\n\n\n[1] 6"
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#packages",
    "href": "310_files/danl-310-quarto-r.html#packages",
    "title": "Quarto with R",
    "section": "",
    "text": "R has a vast collection of packages for various statistical tasks. You can install a package using install.packages(\"packageName\") and load it using library(packageName).\n\n\nCode\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)"
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#help-system",
    "href": "310_files/danl-310-quarto-r.html#help-system",
    "title": "Quarto with R",
    "section": "",
    "text": "To get help on a specific function or topic, use the help() function or the shorthand ?, like ?sum on R Console."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#key-concepts",
    "href": "310_files/danl-310-quarto-r.html#key-concepts",
    "title": "Quarto with R",
    "section": "2.1 Key Concepts",
    "text": "2.1 Key Concepts\n\nData: The raw data that you want to plot.\naes() (Aesthetic Mappings): Defines how data are mapped to color, size, shape, and other visual properties.\nGeoms (Geometric Objects): The type of objects that represent data points, like points, lines, bars, etc.\nFacets: For creating small multiples, splitting data into subsets and displaying the same plot for each subset.\nScales: Control how data values are translated to visual properties.\nCoordinate Systems: The plane in which data is plotted, e.g., Cartesian, polar.\nThemes: Control the overall appearance of the plot, like background color, grid lines, and font sizes."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#examples",
    "href": "310_files/danl-310-quarto-r.html#examples",
    "title": "Quarto with R",
    "section": "2.2 Examples",
    "text": "2.2 Examples\nLet’s go through some examples to illustrate how ggplot can be used to create different types of visualizations.\n\n2.2.1 Scatter Plot\nCreating a scatter plot to explore the relationship between two variables, say mpg (miles per gallon) and wt (weight of the car) from the mtcars dataset.\n\n\nCode\nggplot(mtcars, aes(x = wt, y = mpg)) + \n  geom_point() +\n  labs(x = \"Weight of Car\", y = \"Miles Per Gallon\",\n       title = \"Scatter plot of MPG vs Car Weight\")\n\n\n\n\n\n\n\n\n\nThis code block creates a scatter plot where car weight is on the x-axis and miles per gallon on the y-axis. Each point represents a car.\n\n\n2.2.2 Bar Chart\nCreating a bar chart to show the count of cars by the number of cylinders.\n\n\nCode\nggplot(mtcars, aes(x = factor(cyl))) + \n  geom_bar() + \n  labs(x = \"Number of Cylinders\", y = \"Count\",\n       title = \"Count of Cars by Cylinders\")\n\n\n\n\n\n\n\n\n\nThis plots a bar chart where each bar represents the count of cars with a certain number of cylinders.\n\n\n2.2.3 Line Graph\nPlotting a line graph, assuming we have a time series data.frame economics that is part of ggplot2 package.\n\n\nCode\nggplot(economics, aes(x = date, y = unemploy)) + \n  geom_line() +\n  labs(x = \"Year\", y = \"Number of Unemployed Persons\",\n       title = \"Unemployment over Time\") \n\n\n\n\n\n\n\n\n\nThis code plots the unemployment numbers over time, with time on the x-axis and the number of unemployed persons on the y-axis.\n\n\n2.2.4 Faceted Plot\nCreating a faceted plot to compare scatter plots of mpg vs wt across different numbers of cylinders.\n\n\nCode\nggplot(mtcars, aes(x = wt, y = mpg)) + \n  geom_point() +\n  facet_wrap(~cyl) +\n  labs(title = \"MPG vs Weight by Number of Cylinders\")\n\n\n\n\n\n\n\n\n\nThis splits the data into subsets based on the number of cylinders and creates a scatter plot for each subset."
  },
  {
    "objectID": "310_files/danl-310-quarto-r.html#conclusion",
    "href": "310_files/danl-310-quarto-r.html#conclusion",
    "title": "Quarto with R",
    "section": "2.3 Conclusion",
    "text": "2.3 Conclusion\nggplot2 provides a powerful and flexible system for making a wide variety of plots. By understanding the grammar of graphics upon which it is based, you can build up complex visualizations from simple components, allowing for a deep and intuitive exploration of data."
  },
  {
    "objectID": "320_files/danl-320-python-basic.html",
    "href": "320_files/danl-320-python-basic.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "320_files/danl-320-python-basic.html#what-is-python",
    "href": "320_files/danl-320-python-basic.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\nprint('Hello, World!')"
  },
  {
    "objectID": "320_files/danl-320-python-basic.html#variables-and-data-types",
    "href": "320_files/danl-320-python-basic.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "",
    "text": "In Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n10.5"
  },
  {
    "objectID": "320_files/danl-320-python-basic.html#control-structures",
    "href": "320_files/danl-320-python-basic.html#control-structures",
    "title": "Python Basics",
    "section": "",
    "text": "Python supports the usual logical conditions from mathematics:\n\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\nThese conditions can be used in several ways, most commonly in ‘if statements’ and loops.\n\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "320_files/danl-320-python-basic.html#functions",
    "href": "320_files/danl-320-python-basic.html#functions",
    "title": "Python Basics",
    "section": "",
    "text": "A function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "320_files/danl-320-python-basic.html#lists-and-dictionaries",
    "href": "320_files/danl-320-python-basic.html#lists-and-dictionaries",
    "title": "Python Basics",
    "section": "",
    "text": "A list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "320_files/pandas_basics.html#creating-a-series",
    "href": "320_files/pandas_basics.html#creating-a-series",
    "title": "Pandas Basics",
    "section": "Creating a Series",
    "text": "Creating a Series\n\n\n# Creating a Series from a list\ndata = [10, 20, 30, 40, 50]\nseries = pd.Series(data)\nseries\n\n\n\n\n\n\n\n\n0\n\n\n\n\n0\n10\n\n\n1\n20\n\n\n2\n30\n\n\n3\n40\n\n\n4\n50\n\n\n\n\ndtype: int64"
  },
  {
    "objectID": "320_files/pandas_basics.html#creating-a-dataframe",
    "href": "320_files/pandas_basics.html#creating-a-dataframe",
    "title": "Pandas Basics",
    "section": "Creating a DataFrame",
    "text": "Creating a DataFrame\n\n\n# Creating a DataFrame from a dictionary\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\ndf = pd.DataFrame(data)\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n0\nAlice\n25\nNew York\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "320_files/pandas_basics.html#exploring-data",
    "href": "320_files/pandas_basics.html#exploring-data",
    "title": "Pandas Basics",
    "section": "Exploring Data",
    "text": "Exploring Data\n\n\n# Display the first few rows\ndf.head()\n\n# Display the shape of the DataFrame\nprint(\"Shape:\", df.shape)\n\n# Display summary statistics\ndf.describe()\n\nShape: (3, 3)\n\n\n\n  \n    \n\n\n\n\n\n\nAge\n\n\n\n\ncount\n3.0\n\n\nmean\n30.0\n\n\nstd\n5.0\n\n\nmin\n25.0\n\n\n25%\n27.5\n\n\n50%\n30.0\n\n\n75%\n32.5\n\n\nmax\n35.0"
  },
  {
    "objectID": "320_files/pandas_basics.html#selecting-data",
    "href": "320_files/pandas_basics.html#selecting-data",
    "title": "Pandas Basics",
    "section": "Selecting Data",
    "text": "Selecting Data\n\n# Selecting a single column\ndf[\"Name\"]\n\n\n\n\n\n\n\n\nName\n\n\n\n\n0\nAlice\n\n\n1\nBob\n\n\n2\nCharlie\n\n\n\n\ndtype: object\n\n\n\n# Selecting multiple columns\ndf[[\"Name\", \"City\"]]\n\n\n  \n    \n\n\n\n\n\n\nName\nCity\n\n\n\n\n0\nAlice\nNew York\n\n\n1\nBob\nLos Angeles\n\n\n2\nCharlie\nChicago\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\n# Selecting rows by index\ndf.iloc[0]\n\n\n\n\n\n\n\n\n0\n\n\n\n\nName\nAlice\n\n\nAge\n25\n\n\nCity\nNew York\n\n\n\n\ndtype: object"
  },
  {
    "objectID": "320_files/pandas_basics.html#filtering-data",
    "href": "320_files/pandas_basics.html#filtering-data",
    "title": "Pandas Basics",
    "section": "Filtering Data",
    "text": "Filtering Data\n\n# Filtering rows where Age is greater than 25\nfiltered_df = df[df[\"Age\"] &gt; 25]\nfiltered_df\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\n\n\n\n\n1\nBob\n30\nLos Angeles\n\n\n2\nCharlie\n35\nChicago"
  },
  {
    "objectID": "320_files/pandas_basics.html#adding-a-new-column",
    "href": "320_files/pandas_basics.html#adding-a-new-column",
    "title": "Pandas Basics",
    "section": "Adding a New Column",
    "text": "Adding a New Column\n\n\n# Adding a new column\ndf[\"Salary\"] = [50000, 60000, 70000]\ndf\n\n\n  \n    \n\n\n\n\n\n\nName\nAge\nCity\nSalary\n\n\n\n\n0\nAlice\n25\nNew York\n50000\n\n\n1\nBob\n30\nLos Angeles\n60000\n\n\n2\nCharlie\n35\nChicago\n70000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n    ## Conclusion\n\n    This notebook covers the basic operations of pandas. You can explore more advanced features like merging,\n    joining, and working with time series data in pandas documentation: https://pandas.pydata.org/docs/"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBen & Jerry’s Analysis\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nEmily Peters\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nPySpark Basics\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nEmily Peters\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nGGPlot Basics\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nEmily Peters\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nStarwars\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYour Name\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ben-and-jerrys-310/b-j-blog.html",
    "href": "posts/ben-and-jerrys-310/b-j-blog.html",
    "title": "Ben & Jerry’s Analysis",
    "section": "",
    "text": "library(tidyverse)\nlibrary(skimr)\nlibrary(ggrepel)\n\n\nice_cream &lt;- read_csv('https://bcdanl.github.io/data/ben-and-jerry-cleaned.csv')\nDT::datatable(ice_cream |&gt; head(100))\n\n\n\n\n\n\nDT::datatable(skim(ice_cream))\n\n\n\n\n\n\n\n\nprice_house &lt;- ice_cream |&gt; \n  group_by(household_size) |&gt; \n  summarize(tot_spent = sum(priceper1)) |&gt; \n  arrange(desc(tot_spent)) |&gt; \n  mutate(tot_spent = round(tot_spent, 2))\n\n\nggplot(data = price_house,\n       mapping = aes(x = household_size,\n                     y = tot_spent)) +\n  geom_line(color = \"deepskyblue\", size = 1.5) +\n  geom_point() +\n  theme_minimal() +\n  scale_y_continuous(breaks = c(5000,10000,15000,20000,25000,30000), labels = scales :: dollar) +\n  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +\n  labs(x = \"People per Household\",\n       y = \"Total Money Spent\",\n       title = \"Total Money Spent on Ben and Jerry's \\n Ice Cream by Household Size\") +\n  annotate(\"rect\",\n           xmin = .75, xmax = 2.25,\n           ymin = 17000, ymax = 28500,\n           fill = \"green3\", alpha = .3) +\n  annotate(\"text\",\n           x = 2.5, y = 25000,\n           label = \"Households with a small number of \\n kids or no kids at all buy much more \\n ice cream.\",\n           hjust = 0, size = 3)\n\n\n\n\n\n\n\n\nThis may be suprising results at first look. One might think that larger households would buy more ice cream since there are most likely more children in the household, and ice cream is notably a favorite treat among children. However, for Ben & Jerry’s that is not the case. Here are a couple reasons why:  1. Smaller portions  Ben and Jerry’s is purchased in either 16 ounce or 32 ounce containers (1 or 2 pints). Purchasing enough Ben & Jerry’s ice cream for a larger household will get very expensive. For large families, it would make more financial sense to get a larger container of ice cream of a different brand for the whole family. On the other hand, a smaller container of ice cream would suit households with 1 to 2, or sometimes 3 people. Buying for a smaller amount of people makes Ben and Jerry’s more convenient, which might lead to a smaller household consistantly buying it.  2. Income  Households with 0 children or 1 child will most likely have different budgetary restrictions that than households with multiple children. Obviously, it is much less expensive to support fewer children. Households with multiple children will have to allocate their money differently, which might deter them from buying multiple containers of Ben and Jerry’s consistantly.\n\n\n\n\ntot_spent_flavor &lt;- ice_cream |&gt; \n  group_by(flavor_descr, region) |&gt; \n  summarize(flav_spent = sum(priceper1))\n\n\nggplot(data = tot_spent_flavor,\n       mapping = aes(x = fct_reorder(flavor_descr,\n                                     flav_spent,\n                                     na.rm = T), \n                     y = flav_spent,\n                     fill = flavor_descr))+\n  geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"Central\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"East\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"South\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"West\") |&gt;\n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n  facet_wrap(~ region, \n             scales = \"free_x\",\n             nrow = 1) +\n  theme_bw()+\n  theme(legend.position = \"bottom\",\n        legend.key.size = unit(8, \"pt\"),\n        axis.text.x = element_text(angle = 45,\n                                   size = 4))+\n  scale_fill_viridis_d()+\n  scale_y_continuous(labels = scales :: dollar) +\n  labs(x = \"\",\n       y = \"Total Money Spent\",\n       title = \"Top 5 Flavors Sold by Region\",\n       fill = \"Flavor\")"
  },
  {
    "objectID": "posts/ben-and-jerrys-310/b-j-blog.html#money-spent-on-ben-jerrys-per-flavor",
    "href": "posts/ben-and-jerrys-310/b-j-blog.html#money-spent-on-ben-jerrys-per-flavor",
    "title": "Ben & Jerry’s Analysis",
    "section": "",
    "text": "price_house &lt;- ice_cream |&gt; \n  group_by(household_size) |&gt; \n  summarize(tot_spent = sum(priceper1)) |&gt; \n  arrange(desc(tot_spent)) |&gt; \n  mutate(tot_spent = round(tot_spent, 2))\n\n\nggplot(data = price_house,\n       mapping = aes(x = household_size,\n                     y = tot_spent)) +\n  geom_line(color = \"deepskyblue\", size = 1.5) +\n  geom_point() +\n  theme_minimal() +\n  scale_y_continuous(breaks = c(5000,10000,15000,20000,25000,30000), labels = scales :: dollar) +\n  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9)) +\n  labs(x = \"People per Household\",\n       y = \"Total Money Spent\",\n       title = \"Total Money Spent on Ben and Jerry's \\n Ice Cream by Household Size\") +\n  annotate(\"rect\",\n           xmin = .75, xmax = 2.25,\n           ymin = 17000, ymax = 28500,\n           fill = \"green3\", alpha = .3) +\n  annotate(\"text\",\n           x = 2.5, y = 25000,\n           label = \"Households with a small number of \\n kids or no kids at all buy much more \\n ice cream.\",\n           hjust = 0, size = 3)\n\n\n\n\n\n\n\n\nThis may be suprising results at first look. One might think that larger households would buy more ice cream since there are most likely more children in the household, and ice cream is notably a favorite treat among children. However, for Ben & Jerry’s that is not the case. Here are a couple reasons why:  1. Smaller portions  Ben and Jerry’s is purchased in either 16 ounce or 32 ounce containers (1 or 2 pints). Purchasing enough Ben & Jerry’s ice cream for a larger household will get very expensive. For large families, it would make more financial sense to get a larger container of ice cream of a different brand for the whole family. On the other hand, a smaller container of ice cream would suit households with 1 to 2, or sometimes 3 people. Buying for a smaller amount of people makes Ben and Jerry’s more convenient, which might lead to a smaller household consistantly buying it.  2. Income  Households with 0 children or 1 child will most likely have different budgetary restrictions that than households with multiple children. Obviously, it is much less expensive to support fewer children. Households with multiple children will have to allocate their money differently, which might deter them from buying multiple containers of Ben and Jerry’s consistantly."
  },
  {
    "objectID": "posts/ben-and-jerrys-310/b-j-blog.html#top-10-flavors-sold-by-region",
    "href": "posts/ben-and-jerrys-310/b-j-blog.html#top-10-flavors-sold-by-region",
    "title": "Ben & Jerry’s Analysis",
    "section": "",
    "text": "tot_spent_flavor &lt;- ice_cream |&gt; \n  group_by(flavor_descr, region) |&gt; \n  summarize(flav_spent = sum(priceper1))\n\n\nggplot(data = tot_spent_flavor,\n       mapping = aes(x = fct_reorder(flavor_descr,\n                                     flav_spent,\n                                     na.rm = T), \n                     y = flav_spent,\n                     fill = flavor_descr))+\n  geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"Central\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"East\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"South\") |&gt; \n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n    geom_col(data = tot_spent_flavor |&gt; \n             filter(region == \"West\") |&gt;\n             arrange(desc(flav_spent)) |&gt; \n             head(5)) +\n  facet_wrap(~ region, \n             scales = \"free_x\",\n             nrow = 1) +\n  theme_bw()+\n  theme(legend.position = \"bottom\",\n        legend.key.size = unit(8, \"pt\"),\n        axis.text.x = element_text(angle = 45,\n                                   size = 4))+\n  scale_fill_viridis_d()+\n  scale_y_continuous(labels = scales :: dollar) +\n  labs(x = \"\",\n       y = \"Total Money Spent\",\n       title = \"Top 5 Flavors Sold by Region\",\n       fill = \"Flavor\")"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code with no space in the folder name.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let’s analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs. Droid",
    "text": "Human vs. Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  }
]